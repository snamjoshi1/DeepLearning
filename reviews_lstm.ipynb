{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reviews_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95A0L9TrpQkZ"
      },
      "outputs": [],
      "source": [
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "ipython = get_ipython()\n",
        "ipython.magic(\"sx wget https://www.dropbox.com/s/80yl6pxjx7usk4p/ISB_PyTorch_Tutorial.zip\") \n",
        "!unzip -q ISB_PyTorch_Tutorial.zip\n",
        "!mv ISB_PyTorch_Tutorial/* .\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "torch.use_deterministic_algorithms(False)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "fQyFeXZipZd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Params for training & evaluation\n",
        "dataFileName: TAB separated file having reviews and ratings\n",
        "embeddingDim: Size of Word embeddings. We'll use pretrained FastText Word Embeddings - https://github.com/facebookresearch/MUSE\n",
        "\"\"\"\n",
        "\n",
        "embeddingDim = 300     "
      ],
      "metadata": {
        "id": "9LHFtuDCpdu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJUVlHiapwp7",
        "outputId": "225be12e-e30a-4bef-acad-61dc3a37877a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read the data into a pandas DataFrame. Only the second and third columns are required.\n",
        "The second column is review text and third one is review rating on a scale of 0-10.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "print(\"Started Reading JSON file which contains multiple JSON document\")\n",
        "\n",
        "\n",
        "data = open('/content/drive/MyDrive/reviews.json','r').readlines()\n",
        "result = []\n",
        "for ele in data:\n",
        "    result.append(json.loads(ele))\n",
        "    \n",
        "df = pd.DataFrame.from_dict(result, orient='columns')\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "X2qAhNOjpgCV",
        "outputId": "088888c4-b47f-4d17-9117-e8e74f017eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started Reading JSON file which contains multiple JSON document\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       reviewerID        asin      reviewerName helpful  \\\n",
              "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
              "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
              "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
              "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
              "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
              "5   APX47D16JOP7H  120401325X               RLH  [1, 2]   \n",
              "6  A1JVVYYO7G56DS  120401325X       Tyler Evans  [0, 0]   \n",
              "7   A6FGO4TBZ3QFZ  3998899561  Abdullah Albyati  [1, 2]   \n",
              "8  A2JWEDW5FSVB0F  3998899561              Adam  [2, 3]   \n",
              "9   A8AJS1DW7L3JJ  3998899561   Agata Majchrzak  [1, 1]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  They look good and stick good! I just don't li...      4.0   \n",
              "1  These stickers work like the review says they ...      5.0   \n",
              "2  These are awesome and make my phone look so st...      5.0   \n",
              "3  Item arrived in great time and was in perfect ...      4.0   \n",
              "4  awesome! stays on, and looks great. can be use...      5.0   \n",
              "5  These make using the home button easy. My daug...      3.0   \n",
              "6  Came just as described.. It doesn't come unstu...      5.0   \n",
              "7  it worked for the first week then it only char...      1.0   \n",
              "8  Good case, solid build. Protects phone all aro...      5.0   \n",
              "9  This is a fantastic case. Very stylish and pro...      5.0   \n",
              "\n",
              "                                     summary  unixReviewTime   reviewTime  \n",
              "0                                 Looks Good      1400630400  05 21, 2014  \n",
              "1                      Really great product.      1389657600  01 14, 2014  \n",
              "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
              "3                                      Cute!      1382313600  10 21, 2013  \n",
              "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  \n",
              "5                                       Cute      1381536000  10 12, 2013  \n",
              "6                          best thing ever..      1377129600  08 22, 2013  \n",
              "7                            not a good Idea      1384992000  11 21, 2013  \n",
              "8                                 Solid Case      1380067200  09 25, 2013  \n",
              "9                               Perfect Case      1396483200   04 3, 2014  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-510c4b1a-47d0-43a2-bd2b-6ee4edb82080\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A30TL5EWN6DFXT</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>christina</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>They look good and stick good! I just don't li...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Looks Good</td>\n",
              "      <td>1400630400</td>\n",
              "      <td>05 21, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ASY55RVNIL0UD</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>emily l.</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>These stickers work like the review says they ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Really great product.</td>\n",
              "      <td>1389657600</td>\n",
              "      <td>01 14, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2TMXE2AFO7ONB</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>Erica</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>These are awesome and make my phone look so st...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>LOVE LOVE LOVE</td>\n",
              "      <td>1403740800</td>\n",
              "      <td>06 26, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AWJ0WZQYMYFQ4</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>JM</td>\n",
              "      <td>[4, 4]</td>\n",
              "      <td>Item arrived in great time and was in perfect ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cute!</td>\n",
              "      <td>1382313600</td>\n",
              "      <td>10 21, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ATX7CZYFXI1KW</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>patrice m rogoza</td>\n",
              "      <td>[2, 3]</td>\n",
              "      <td>awesome! stays on, and looks great. can be use...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>leopard home button sticker for iphone 4s</td>\n",
              "      <td>1359849600</td>\n",
              "      <td>02 3, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>APX47D16JOP7H</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>RLH</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>These make using the home button easy. My daug...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Cute</td>\n",
              "      <td>1381536000</td>\n",
              "      <td>10 12, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A1JVVYYO7G56DS</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>Tyler Evans</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Came just as described.. It doesn't come unstu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>best thing ever..</td>\n",
              "      <td>1377129600</td>\n",
              "      <td>08 22, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A6FGO4TBZ3QFZ</td>\n",
              "      <td>3998899561</td>\n",
              "      <td>Abdullah Albyati</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>it worked for the first week then it only char...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>not a good Idea</td>\n",
              "      <td>1384992000</td>\n",
              "      <td>11 21, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A2JWEDW5FSVB0F</td>\n",
              "      <td>3998899561</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[2, 3]</td>\n",
              "      <td>Good case, solid build. Protects phone all aro...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Solid Case</td>\n",
              "      <td>1380067200</td>\n",
              "      <td>09 25, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A8AJS1DW7L3JJ</td>\n",
              "      <td>3998899561</td>\n",
              "      <td>Agata Majchrzak</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>This is a fantastic case. Very stylish and pro...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Perfect Case</td>\n",
              "      <td>1396483200</td>\n",
              "      <td>04 3, 2014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-510c4b1a-47d0-43a2-bd2b-6ee4edb82080')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-510c4b1a-47d0-43a2-bd2b-6ee4edb82080 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-510c4b1a-47d0-43a2-bd2b-6ee4edb82080');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df=df[['reviewText','overall']]\n",
        "data_df.head()\n",
        "#Changing the overall ratings to 0 to 4 from 1 to 5.This helps as we have used crossentropyloss below.\n",
        "data_df['overall']=data_df['overall']-1\n",
        "data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ndXDYD__prs_",
        "outputId": "632e30e7-55c1-4568-c83c-b827e6f74688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          reviewText  overall\n",
              "0  They look good and stick good! I just don't li...      3.0\n",
              "1  These stickers work like the review says they ...      4.0\n",
              "2  These are awesome and make my phone look so st...      4.0\n",
              "3  Item arrived in great time and was in perfect ...      3.0\n",
              "4  awesome! stays on, and looks great. can be use...      4.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4231a505-e115-4839-93b0-1e99e77ac81e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>They look good and stick good! I just don't li...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>These stickers work like the review says they ...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>These are awesome and make my phone look so st...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Item arrived in great time and was in perfect ...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>awesome! stays on, and looks great. can be use...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4231a505-e115-4839-93b0-1e99e77ac81e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4231a505-e115-4839-93b0-1e99e77ac81e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4231a505-e115-4839-93b0-1e99e77ac81e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Let's take a quick look at the distribution of different ratings\n",
        "\"\"\"\n",
        "rating_frequency_count = data_df.overall.value_counts()\n",
        "sns.barplot(x=rating_frequency_count.index, y=rating_frequency_count.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pglzIIk2p6Av",
        "outputId": "48b09188-f9cb-434d-d258-e06ae01cce43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbe653c1310>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Now let's find out a value for maxlen. For that, we first look at the distribution of review lengths in terms of \n",
        "number of words. A box plot is used to visualize this distribution.\n",
        "\"\"\"\n",
        "\n",
        "re_wordMatcher = re.compile(r'[a-z0-9]+') #Declare regex to extract words\n",
        "numWords = data_df[\"reviewText\"].map(lambda x: len(re_wordMatcher.findall(x.lower())))\n",
        "g = sns.boxplot(numWords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "IYqjVi17p93w",
        "outputId": "838dd312-c249-4b0d-e34f-f02ee58e4e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The above plot shows that there are few very long reviews (black dots on the right) but most of the reviews are\n",
        "comparatively shorter than around 250 words. Specifically, let's find the 90th quantile of the review length. \n",
        "\"\"\"\n",
        "\n",
        "reviewLen90 = np.quantile(numWords, 0.90)\n",
        "print(\"90th quantile of review length:\", reviewLen90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwV-k5i1qBnc",
        "outputId": "7f8f37f7-c33d-41f6-e2f0-2b6e2695acfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90th quantile of review length: 214.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Thus, 90% of reviews are of 191 words or shorter. We'll set maxlen close to this.\n",
        "\"\"\"\n",
        "maxlen = 214"
      ],
      "metadata": {
        "id": "eyxk5BdKqE3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lets's create training and test datasets by keeping ratio between the positive and negative labels same.\n",
        "We use sklearn.model_selection.StratifiedKFold setting number of folds (n_splits) = 5, which splits the data into\n",
        "80% train and 20% test and for 5 folds. But we keep only the first fold for this demo.\n",
        "\"\"\"\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "for trn_idx, tst_idx in skf.split(data_df['reviewText'],data_df['overall']):\n",
        "    break\n",
        "\n",
        "train_df, test_df = data_df.iloc[trn_idx], data_df.iloc[tst_idx]\n",
        "\n",
        "print(\"Shape of train and test dataframes:\", train_df.shape, test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPazOiazqIUC",
        "outputId": "84ef3c13-9606-4727-b24c-d123f1554999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train and test dataframes: (155551, 2) (38888, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read FastText En model. If the file wiki.multi.en.vec' does not exist, download it from \n",
        "# https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec\n",
        "!pip install wget\n",
        "import wget\n",
        "word2VecFile = os.path.join(os.curdir, 'wiki.multi.en.vec')\n",
        "\n",
        "if os.path.exists(word2VecFile):\n",
        "    print('Word2Vec file has been found and is being loaded...')\n",
        "else:    \n",
        "    print('Word2Vec file does not exist and needs to be downloaded')\n",
        "    url = 'https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec'\n",
        "    wget.download(url)\n",
        "    print('Downloading from', url)\n",
        "en_model = KeyedVectors.load_word2vec_format('wiki.multi.en.vec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6g3KdYWqLro",
        "outputId": "21cbec15-ab87-4701-f63a-35f03d76c1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=66eb6d73f8e4e4b93848c8fde7b0c772b5b49d192f48fdbb6610350d071c1cd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Word2Vec file does not exist and needs to be downloaded\n",
            "Downloading from https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Now let us create a numpy array containing the word vectors. Later this numpy array will be used for initilaizing \n",
        "the embedding layer in the model.\n",
        "\"\"\"\n",
        "\n",
        "vocab = list(en_model.vocab.keys())\n",
        "print(\"Vocab size in pretrained model:\", len(vocab))\n",
        "\n",
        "# check if the word 'and' is present in the pretrained model\n",
        "assert \"and\" in en_model\n",
        "\n",
        "# check the dimension of the word vectors\n",
        "assert embeddingDim == len(en_model[\"and\"])\n",
        "\n",
        "# initialize a numpy matrix which will store the word vectors\n",
        "# first row is for the padding token\n",
        "pretrained_weights = np.zeros((1+len(vocab), embeddingDim))\n",
        "\n",
        "# tqdm just adds a progress bar\n",
        "for i, token in enumerate(vocab):\n",
        "    pretrained_weights[i, :] = en_model[token]\n",
        "\n",
        "# map tokens in the vocab to ids\n",
        "vocab = dict(zip(vocab, range(1, len(vocab)+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y2lLdLEqOMP",
        "outputId": "3933701b-2ab7-4591-c373-f8ebbbe7f299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size in pretrained model: 200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reviewText2Features(reviewText):\n",
        "    \"\"\"\n",
        "    Function which takes review text (basically a string!) as input and returns a features matrix X of shape\n",
        "    (maxlen, embeddingDim). This is done by splitting the review into words and then representing each word by it's\n",
        "    word vector obtained from the Word2Vec model. Sentences having more than maxlen words are truncated while shorter\n",
        "    ones are zero-padded by pre-adding all zero vectors.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    \n",
        "    reviewWords = re_wordMatcher.findall(reviewText.lower())\n",
        "    \n",
        "    \"\"\"\n",
        "    Tokenize the review using the word-matching regex and get its word vector from the pretrained Word2Vec model.\n",
        "    Words not found in the Word2Vec model are ignored\n",
        "    \"\"\"\n",
        "    for i, word in enumerate(reviewWords):\n",
        "        if word not in en_model:\n",
        "            continue\n",
        "        if i >= maxlen:\n",
        "            break\n",
        "        # X.append(en_model[word])\n",
        "        X.append(vocab[word])\n",
        "    \n",
        "    \"\"\"\n",
        "    Add zero padding in the begining of the sequence if the number of words is less than maxlen.\n",
        "    \"\"\"\n",
        "    if len(X) < maxlen:\n",
        "        # zero_padding = [[0.]*embeddingDim]*(maxlen - len(X))\n",
        "        zero_padding = [0.]*(maxlen - len(X))\n",
        "        X = zero_padding + X\n",
        "    \n",
        "    return X # np.array(X)\n",
        "        \n",
        "def row2Features(row):\n",
        "    \"\"\"\n",
        "    Function which takes a datafram row as input and produces features and labels.\n",
        "    \n",
        "    Input: row | Type: pandas.core.series.Series\n",
        "    \n",
        "    Output: X, y | Type: X - np.ndarray of shape (maxlen, embeddingDim) & y - int where Positive = 0 & Negative = 1\n",
        "    \"\"\"    \n",
        "    \n",
        "    X = reviewText2Features(row[\"reviewText\"])\n",
        "    y = row[\"overall\"]\n",
        "        \n",
        "    return X, y"
      ],
      "metadata": {
        "id": "DOC890DOqQZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Now apply the above function on a sample row\n",
        "\"\"\"\n",
        "sampleRow = data_df.iloc[0]\n",
        "reviewWords = re_wordMatcher.findall(sampleRow[\"reviewText\"].lower())\n",
        "print(\"Review:\", sampleRow[\"reviewText\"])\n",
        "print(\"Rating:\", sampleRow[\"overall\"])\n",
        "print(\"Review words:\", reviewWords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37rmV5ZOqTLp",
        "outputId": "73e7daae-aad5-4db1-b407-6cd284ebae83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\n",
            "Rating: 3.0\n",
            "Review words: ['they', 'look', 'good', 'and', 'stick', 'good', 'i', 'just', 'don', 't', 'like', 'the', 'rounded', 'shape', 'because', 'i', 'was', 'always', 'bumping', 'it', 'and', 'siri', 'kept', 'popping', 'up', 'and', 'it', 'was', 'irritating', 'i', 'just', 'won', 't', 'buy', 'a', 'product', 'like', 'this', 'again']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Give the sample row to the function row2Features\n",
        "\"\"\"\n",
        "X, y = row2Features(sampleRow)\n",
        "print(\"Dimension of X:\", len(X))\n",
        "print(\"Label y:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_meVJCqXRF",
        "outputId": "dfbcd297-f338-491b-c949-3b8b2b40d575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of X: 214\n",
            "Label y: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffleArray(X, y):\n",
        "    idx = np.arange(X.shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    X = X[idx, :]\n",
        "    y = y[idx]\n",
        "    return X, y\n",
        "\n",
        "def generateModelReadyData(data, batchSize = 128, shuffle=False):\n",
        "    \"\"\"\n",
        "    Generator function which generates features and labels in batches\n",
        "    \n",
        "    Input:\n",
        "    data - DataFrame where each row has review and sentiment\n",
        "    batchSize - No. of rows for which features will be created and returned in a batch.\n",
        "    Note: This is useful for running mini-batch Gradient Descent optimization when the dataset is large.\n",
        "    \n",
        "    Output:\n",
        "    X - 3D np.ndarray of shape (batchSize, maxlen, embeddingDim)\n",
        "    y - 1D np. array of shape (batchSize,)        \n",
        "    \"\"\"\n",
        "    \n",
        "    while(True):\n",
        "        X = []\n",
        "        y = []\n",
        "        for _, row in data.iterrows():\n",
        "            \"\"\"Generate features and label for this row\"\"\"\n",
        "            X_, y_ = row2Features(row)\n",
        "\n",
        "            \"\"\"Keep accumulating the row-wise features\"\"\"\n",
        "            X.append(X_)\n",
        "            y.append(y_)   \n",
        "\n",
        "            \"\"\"If number of rows processed is greater than batchSize yield the batch and trim down X & y\n",
        "            Note: This way we avoid running into memory issues by not bloating X and y bigger and bigger\n",
        "            \"\"\"\n",
        "            if len(X) > batchSize:\n",
        "                temp_X, temp_y = np.array(X[:batchSize]), np.array(y[:batchSize])\n",
        "                if shuffle:\n",
        "                    temp_X, temp_y = shuffleArray(temp_X, temp_y)\n",
        "                \n",
        "                X, y = X[batchSize:], y[batchSize:]                    \n",
        "                yield temp_X, temp_y\n",
        "\n",
        "        \"\"\"Yield the remaining few rows when number of rows in data isn't a mutiple of batchSize\"\"\"\n",
        "        if len(X) > 0:\n",
        "            temp_X, temp_y = np.array(X), np.array(y)\n",
        "            if shuffle:\n",
        "                temp_X, temp_y = shuffleArray(temp_X, temp_y)\n",
        "            \n",
        "            yield temp_X, temp_y"
      ],
      "metadata": {
        "id": "uXcn1DDfqZ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Let's test the generator function for few batches\"\"\"\n",
        "numBatches = 0\n",
        "for i, (X, y) in enumerate(generateModelReadyData(data_df, batchSize=128, shuffle=True)):\n",
        "    if numBatches >= 3:\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "        print(\"Batch:\", i)\n",
        "        assert X.shape == (128, maxlen)\n",
        "        assert y.shape == (128,)\n",
        "        print(\"Shape of X & y matches expected values\")\n",
        "    numBatches += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSjsctIjqcUe",
        "outputId": "ecff887d-6d77-4ffe-922a-b06e0ee432c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0\n",
            "Shape of X & y matches expected values\n",
            "Batch: 1\n",
            "Shape of X & y matches expected values\n",
            "Batch: 2\n",
            "Shape of X & y matches expected values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    print(\"cuda available\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hRnbZsqe4m",
        "outputId": "4e003d32-4c6e-4af9-f5df-f27b2b798f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Set random number seed using torch.manual_seed to make sure the same seed is used\n",
        "by the Pytorch backend and hence ensure repeatable results\n",
        "\"\"\"\n",
        "#Seed 1\n",
        "#torch.manual_seed(500)\n",
        "#random.seed(400)\n",
        "#np.random.seed(0)\n",
        "\n",
        "#Seed 2\n",
        "#torch.manual_seed(600)\n",
        "#random.seed(450)\n",
        "#np.random.seed(10)\n",
        "\n",
        "#Seed 3\n",
        "torch.manual_seed(700)\n",
        "random.seed(500)\n",
        "np.random.seed(20)"
      ],
      "metadata": {
        "id": "snVDYDPaqgq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, pretrained_weights):\n",
        "        super(SentimentNet, self).__init__()\n",
        "        \n",
        "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_weights))\n",
        "        \n",
        "        \"\"\"\n",
        "        Adding a dropout layer to force some of the feature values to zero.\n",
        "        Note: Dropout is a regularization technique which sets the activation of few randomly chosen neurons of\n",
        "        a hidden layer to zero. It can also be applied to the input layer where some of the input features are set to zero.\n",
        "        For more details refer http://jmlr.org/papers/v15/srivastava14a.html\n",
        "        \"\"\"\n",
        "        self.sentInputDropout = nn.Dropout(0.1)\n",
        "        \n",
        "        \"\"\"\n",
        "        Now let's stack a couple of bidirectional RNNs to process the input sequence and extract features\n",
        "        \"\"\"\n",
        "        self.biLSTM1 = nn.LSTM(embedding_dim, hidden_dim[0], bidirectional=True, batch_first=True)\n",
        "        self.biLSTMDropOut = nn.Dropout(0.1)\n",
        "        self.dense1 = nn.Linear(2*hidden_dim[0], 50)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.outputLayer = nn.Linear(50, 5)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_len = x.shape[0]\n",
        "        out = self.embedding(x)\n",
        "        out = self.sentInputDropout(out)\n",
        "        out, hidden = self.biLSTM1(out)\n",
        "        out = self.biLSTMDropOut(out)\n",
        "\n",
        "        out = self.dense1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.dropout2(out)\n",
        "        out = self.outputLayer(out)\n",
        "        out = out[:,-1]\n",
        "        return out    "
      ],
      "metadata": {
        "id": "Hl4ATp_EqgxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentNet(embeddingDim, [100], 1+len(vocab), pretrained_weights)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqC3H2SHqmrO",
        "outputId": "85512bbe-f445-4ac4-e30d-6087bb67860b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentNet(\n",
              "  (embedding): Embedding(200001, 300)\n",
              "  (sentInputDropout): Dropout(p=0.1, inplace=False)\n",
              "  (biLSTM1): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
              "  (biLSTMDropOut): Dropout(p=0.1, inplace=False)\n",
              "  (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (dropout2): Dropout(p=0.1, inplace=False)\n",
              "  (outputLayer): Linear(in_features=50, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.7\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "9OOaaaeyqqXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "counter = 0\n",
        "print_every = 500\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "gamma=0.9\n",
        "\n",
        "model = model.float()\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    print(\"Epoch:\", i+1)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma-(0.001/((epochs+1)-i)))\n",
        "    scheduler.step()\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    print(lr)\n",
        "    print(\"Running a pass over the training data...\")\n",
        "    for j, (inputs, labels) in enumerate(generateModelReadyData(train_df, batchSize=128, shuffle=True)):\n",
        "        if j >= np.ceil(train_df.shape[0]/128):\n",
        "            break\n",
        "        \n",
        "    #for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        inputs, labels = torch.from_numpy(inputs), torch.from_numpy(labels)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs.long())\n",
        "       \n",
        "        loss = criterion(output, labels.type(torch.LongTensor).to(device))\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()        \n",
        "        if (j+1) % 100 == 0:\n",
        "            print(\"Batches completed:\", j+1)\n",
        "    \n",
        "    print(\"Batches completed:\", j+1)\n",
        "    val_losses = []\n",
        "    model.eval()\n",
        "    print(\"Running a pass over the test data...\")\n",
        "    for k, (inp, lab) in enumerate(generateModelReadyData(test_df, batchSize=128, shuffle=False)):\n",
        "        if k >= np.ceil(test_df.shape[0]/128):\n",
        "            break\n",
        "        inp, lab = torch.from_numpy(inp), torch.from_numpy(lab)\n",
        "        inp, lab = inp.to(device), lab.to(device)\n",
        "        out = model(inp.long())\n",
        "        val_loss = criterion(out.squeeze(), lab.type(torch.LongTensor).to(device))\n",
        "        val_losses.append(val_loss.item())\n",
        "        if (k+1) % 100 == 0:\n",
        "            print(\"Batches completed:\", k+1)\n",
        "    \n",
        "    print(\"Batches completed:\", k+1)\n",
        "\n",
        "    model.train()\n",
        "    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "          \"Step: {}...\".format(counter),\n",
        "          \"Loss: {:.6f}...\".format(loss.item()),\n",
        "          \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "    if np.mean(val_losses) <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), './state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
        "        valid_loss_min = np.mean(val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4cO5G-xrH8Q",
        "outputId": "fbce9dd0-52fe-439c-b993-d89b0f4c2996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "0.6299363636363636\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 1/10... Step: 1216... Loss: 0.328783... Val Loss: 1.472584\n",
            "Validation loss decreased (inf --> 1.472584).  Saving model ...\n",
            "Epoch: 2\n",
            "0.5668797336363637\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 2/10... Step: 2432... Loss: 0.335515... Val Loss: 1.456572\n",
            "Validation loss decreased (1.472584 --> 1.456572).  Saving model ...\n",
            "Epoch: 3\n",
            "0.5101287736356567\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 3/10... Step: 3648... Loss: 0.342988... Val Loss: 1.439425\n",
            "Validation loss decreased (1.456572 --> 1.439425).  Saving model ...\n",
            "Epoch: 4\n",
            "0.45905213017538654\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 4/10... Step: 4864... Loss: 0.348591... Val Loss: 1.426637\n",
            "Validation loss decreased (1.439425 --> 1.426637).  Saving model ...\n",
            "Epoch: 5\n",
            "0.4130813382821086\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 5/10... Step: 6080... Loss: 0.353585... Val Loss: 1.415705\n",
            "Validation loss decreased (1.426637 --> 1.415705).  Saving model ...\n",
            "Epoch: 6\n",
            "0.3717043575641841\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 6/10... Step: 7296... Loss: 0.358142... Val Loss: 1.406228\n",
            "Validation loss decreased (1.415705 --> 1.406228).  Saving model ...\n",
            "Epoch: 7\n",
            "0.33445958093625283\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 7/10... Step: 8512... Loss: 0.362018... Val Loss: 1.398461\n",
            "Validation loss decreased (1.406228 --> 1.398461).  Saving model ...\n",
            "Epoch: 8\n",
            "0.3009300079473935\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 8/10... Step: 9728... Loss: 0.365148... Val Loss: 1.392328\n",
            "Validation loss decreased (1.398461 --> 1.392328).  Saving model ...\n",
            "Epoch: 9\n",
            "0.27073669715000503\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 9/10... Step: 10944... Loss: 0.367984... Val Loss: 1.387055\n",
            "Validation loss decreased (1.392328 --> 1.387055).  Saving model ...\n",
            "Epoch: 10\n",
            "0.24352765908642954\n",
            "Running a pass over the training data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 400\n",
            "Batches completed: 500\n",
            "Batches completed: 600\n",
            "Batches completed: 700\n",
            "Batches completed: 800\n",
            "Batches completed: 900\n",
            "Batches completed: 1000\n",
            "Batches completed: 1100\n",
            "Batches completed: 1200\n",
            "Batches completed: 1217\n",
            "Running a pass over the test data...\n",
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Epoch: 10/10... Step: 12160... Loss: 0.372416... Val Loss: 1.379488\n",
            "Validation loss decreased (1.387055 --> 1.379488).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "At this point we can load a pretrained model which was trained for 5 epochs and make predictions using it.\n",
        "Uncomment and run the below line to load the pretrained model\n",
        "\"\"\"\n",
        "model.load_state_dict(torch.load('./state_dict.pt'))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONWzH7wKrLzx",
        "outputId": "9a1d80a3-8c82-47ff-a2cf-1553bc154328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentNet(\n",
              "  (embedding): Embedding(200001, 300)\n",
              "  (sentInputDropout): Dropout(p=0.1, inplace=False)\n",
              "  (biLSTM1): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
              "  (biLSTMDropOut): Dropout(p=0.1, inplace=False)\n",
              "  (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (dropout2): Dropout(p=0.1, inplace=False)\n",
              "  (outputLayer): Linear(in_features=50, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "pred_proba = []\n",
        "actual = []\n",
        "\n",
        "model.eval()\n",
        "for j, (X_test, y_test) in enumerate(generateModelReadyData(test_df, batchSize=128)):\n",
        "    if j >= np.ceil(test_df.shape[0]/128):\n",
        "        break\n",
        "    \n",
        "    inputs_test, labels_test = torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
        "    inputs_test, labels_test = inputs_test.to(device), labels_test.to(device)\n",
        "    output_test = model(inputs_test.long())\n",
        "    test_loss = criterion(output_test.squeeze(), labels_test.type(torch.LongTensor).to(device))\n",
        "    test_losses.append(test_loss.item())\n",
        "    _, predicted = torch.max(output_test, 1) \n",
        "    correct_tensor = predicted.eq(labels_test.long())\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    pred_proba.extend(output_test.cpu().squeeze().detach().numpy())\n",
        "    actual.extend(y_test)\n",
        "    \n",
        "    if (j+1) % 100 == 0:\n",
        "        print(\"Batches completed:\", j+1)\n",
        "\n",
        "print(\"Batches completed:\", j+1)\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "test_acc = num_correct/len(test_df)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izmd3P6qrN8G",
        "outputId": "47ac39a1-7c53-4edd-eb60-31415cc0b412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches completed: 100\n",
            "Batches completed: 200\n",
            "Batches completed: 300\n",
            "Batches completed: 305\n",
            "Test loss: 1.379\n",
            "Test accuracy: 55.886%\n"
          ]
        }
      ]
    }
  ]
}