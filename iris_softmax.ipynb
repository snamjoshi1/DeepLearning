{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_softmax.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 761,
      "metadata": {
        "id": "86ww-q5gAXaV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch as t\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Seed 1\n",
        "#torch.manual_seed(299)\n",
        "#random.seed(53)\n",
        "#np.random.seed(100)\n",
        "\n",
        "#Seed 2\n",
        "#torch.manual_seed(798)\n",
        "#random.seed(50)\n",
        "#np.random.seed(20)\n",
        "\n",
        "#Seed 3\n",
        "torch.manual_seed(500)\n",
        "random.seed(55)\n",
        "np.random.seed(9)\n",
        "\n",
        "\n",
        "\n",
        "torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "id": "SZ23pfoBC1Fe"
      },
      "execution_count": 762,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import TensorDataset\n",
        "# choose the training and test datasets\n",
        "iris_train_load=pd.read_csv('/content/iris_training.csv',header=None)\n",
        "iris_train_load\n",
        "\n",
        "\n",
        "input=iris_train_load.iloc[:,:4]\n",
        "print('\\nInput values are:') \n",
        "print(input.head())\n",
        "\n",
        "output=iris_train_load.iloc[:,4:5]\n",
        "print('\\nThe output value is:') \n",
        "print(output.head()) \n",
        "\n",
        "\n",
        "# Convert Input and Output data to Tensors and create a TensorDataset \n",
        "input = torch.Tensor(input.to_numpy())      # Create tensor of type torch.float32 \n",
        "print('\\nInput format: ', input.shape, input.dtype)     # Input format: torch.Size([120, 4]) torch.float32 \n",
        "output = torch.tensor(output.to_numpy())        # Create tensor type torch.int64  \n",
        "print('Output format: ', output.shape, output.dtype)  # Output format: torch.Size([120, 1]) torch.int64 \n",
        "data_train = TensorDataset(input, output)  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "iris_test_load=pd.read_csv('/content/iris_test.csv',header=None)\n",
        "input_test=iris_test_load.iloc[:,:4]\n",
        "print('\\nInput values are:') \n",
        "print(input_test.head())\n",
        "\n",
        "output_test=iris_test_load.iloc[:,4:5]\n",
        "print('\\nThe output value is:') \n",
        "print(output_test.head()) \n",
        "\n",
        "\n",
        "# Convert Input and Output data to Tensors and create a TensorDataset \n",
        "input_test = torch.Tensor(input_test.to_numpy())      # Create tensor of type torch.float32 \n",
        "print('\\nInput format: ', input_test.shape, input_test.dtype)     # Input format: torch.Size([30, 4]) torch.float32 \n",
        "output_test = torch.tensor(output_test.to_numpy())        # Create tensor type torch.int64  \n",
        "print('Output format: ', output_test.shape, output_test.dtype)  # Output format: torch.Size([30, 1]) torch.int64 \n",
        "data_test = TensorDataset(input_test, output_test)  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5IC_orqC1N1",
        "outputId": "e2e3486d-fa2e-4799-eb5d-77f18a27895c"
      },
      "execution_count": 763,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input values are:\n",
            "     0    1    2    3\n",
            "0  6.4  2.8  5.6  2.2\n",
            "1  5.0  2.3  3.3  1.0\n",
            "2  4.9  2.5  4.5  1.7\n",
            "3  4.9  3.1  1.5  0.1\n",
            "4  5.7  3.8  1.7  0.3\n",
            "\n",
            "The output value is:\n",
            "   4\n",
            "0  2\n",
            "1  1\n",
            "2  2\n",
            "3  0\n",
            "4  0\n",
            "\n",
            "Input format:  torch.Size([120, 4]) torch.float32\n",
            "Output format:  torch.Size([120, 1]) torch.int64\n",
            "\n",
            "Input values are:\n",
            "     0    1    2    3\n",
            "0  5.9  3.0  4.2  1.5\n",
            "1  6.9  3.1  5.4  2.1\n",
            "2  5.1  3.3  1.7  0.5\n",
            "3  6.0  3.4  4.5  1.6\n",
            "4  5.5  2.5  4.0  1.3\n",
            "\n",
            "The output value is:\n",
            "   4\n",
            "0  1\n",
            "1  2\n",
            "2  0\n",
            "3  1\n",
            "4  1\n",
            "\n",
            "Input format:  torch.Size([30, 4]) torch.float32\n",
            "Output format:  torch.Size([30, 1]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 20\n",
        "number_rows = len(input)    # The size of our dataset or the number of rows in excel table.  \n",
        "val_split = int(number_rows*0.3)  \n",
        "train_split = number_rows - val_split   \n",
        "train_set, validate_set= torch.utils.data.random_split( \n",
        "    data_train, [train_split, val_split])    \n",
        " \n",
        "# Create Dataloader to read the data within batch sizes and put into memory. \n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=train_batch_size ) \n",
        "validate_loader = torch.utils.data.DataLoader(validate_set,batch_size=1) \n",
        "test_loader = torch.utils.data.DataLoader(data_test,batch_size=1)"
      ],
      "metadata": {
        "id": "hhBW8RUnD7-1"
      },
      "execution_count": 764,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the NN architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 3) \n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #output = F.softmax(x,dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "# initialize the NN\n",
        "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m25m1lWeC1UU",
        "outputId": "752fa0c6-706d-490a-8810-68b1a939000b"
      },
      "execution_count": 765,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=4, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Specify loss and optimization functions\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.09)\n",
        "\n",
        "print(criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFXvc67vErZz",
        "outputId": "e707e0cf-6071-4a46-dd1b-8eb19611b882"
      },
      "execution_count": 766,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrossEntropyLoss() Adagrad (\n",
            "Parameter Group 0\n",
            "    eps: 1e-10\n",
            "    initial_accumulator_value: 0\n",
            "    lr: 0.09\n",
            "    lr_decay: 0\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function \n",
        "def train(num_epochs): \n",
        "    best_accuracy = 0.0 \n",
        "     \n",
        "    print(\"Begin training...\") \n",
        "    for epoch in range(1, num_epochs+1): \n",
        "        running_train_loss = 0.0 \n",
        "        running_accuracy = 0.0 \n",
        "        running_vall_loss = 0.0 \n",
        "        total = 0 \n",
        " \n",
        "        # Training Loop \n",
        "        for data in train_loader: \n",
        "        #for data in enumerate(train_loader, 0): \n",
        "            inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs] \n",
        "            optimizer.zero_grad()   # zero the parameter gradients          \n",
        "            predicted_outputs = model(inputs)   # predict output from the model \n",
        "            train_loss = criterion(predicted_outputs, torch.flatten(outputs))   # calculate loss for the predicted output  \n",
        "            train_loss.backward()   # backpropagate the loss \n",
        "            optimizer.step()        # adjust parameters based on the calculated gradients \n",
        "            running_train_loss +=train_loss.item()  # track the loss value \n",
        " \n",
        "        # Calculate training loss value \n",
        "        train_loss_value = running_train_loss/len(train_loader) \n",
        " \n",
        "        # Validation Loop \n",
        "        with torch.no_grad(): \n",
        "          model.eval() \n",
        "          for data in validate_loader: \n",
        "            inputs, outputs = data \n",
        "            predicted_outputs = model(inputs) \n",
        "            val_loss = criterion(predicted_outputs, torch.flatten(outputs)) \n",
        "             \n",
        "            # The label with the highest value will be our prediction \n",
        "            _, predicted = torch.max(predicted_outputs, 1)\n",
        "            running_vall_loss += val_loss.item()  \n",
        "            total += outputs.size(0) \n",
        "            running_accuracy += (predicted.eq(torch.flatten(outputs))).sum().item() \n",
        "\n",
        " \n",
        "        # Calculate validation loss value \n",
        "        val_loss_value = running_vall_loss/len(validate_loader) \n",
        "                \n",
        "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
        "        accuracy = (100 * running_accuracy / total)     \n",
        "\n",
        "         \n",
        "        # Print the statistics of the epoch \n",
        "        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))"
      ],
      "metadata": {
        "id": "RM5MWg8IEtT2"
      },
      "execution_count": 767,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test the model \n",
        "def test(): \n",
        "    total=0.0\n",
        "    running_accuracy=0.0\n",
        "    with torch.no_grad(): \n",
        "        for data in test_loader: \n",
        "            inputs, outputs = data \n",
        "            outputs = outputs.to(torch.float32) \n",
        "            predicted_outputs = model(inputs) \n",
        "            _, predicted = torch.max(predicted_outputs, 1) \n",
        "            total += outputs.size(0) \n",
        "            running_accuracy += (predicted == torch.flatten(outputs)).sum().item() \n",
        " \n",
        "        print('Test Accuracy is: %d %%' % (100 * running_accuracy / total))   "
      ],
      "metadata": {
        "id": "loA-ewYjE1ZH"
      },
      "execution_count": 768,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": \n",
        "    num_epochs = 1000\n",
        "    train(num_epochs) \n",
        "    print('Finished Training\\n') \n",
        "    test() \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw4PdSP5E3e0",
        "outputId": "fe1902b6-e60e-4afc-81a9-18becfd77bc0"
      },
      "execution_count": 769,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training...\n",
            "Completed training batch 1 Training Loss is: 1.2560 Validation Loss is: 0.8376 Accuracy is 69 %\n",
            "Completed training batch 2 Training Loss is: 0.7869 Validation Loss is: 0.7429 Accuracy is 69 %\n",
            "Completed training batch 3 Training Loss is: 0.7045 Validation Loss is: 0.6912 Accuracy is 69 %\n",
            "Completed training batch 4 Training Loss is: 0.6554 Validation Loss is: 0.6555 Accuracy is 69 %\n",
            "Completed training batch 5 Training Loss is: 0.6209 Validation Loss is: 0.6286 Accuracy is 69 %\n",
            "Completed training batch 6 Training Loss is: 0.5947 Validation Loss is: 0.6072 Accuracy is 69 %\n",
            "Completed training batch 7 Training Loss is: 0.5738 Validation Loss is: 0.5896 Accuracy is 69 %\n",
            "Completed training batch 8 Training Loss is: 0.5566 Validation Loss is: 0.5754 Accuracy is 69 %\n",
            "Completed training batch 9 Training Loss is: 0.5422 Validation Loss is: 0.5629 Accuracy is 69 %\n",
            "Completed training batch 10 Training Loss is: 0.5297 Validation Loss is: 0.5516 Accuracy is 69 %\n",
            "Completed training batch 11 Training Loss is: 0.5187 Validation Loss is: 0.5416 Accuracy is 69 %\n",
            "Completed training batch 12 Training Loss is: 0.5089 Validation Loss is: 0.5326 Accuracy is 69 %\n",
            "Completed training batch 13 Training Loss is: 0.5000 Validation Loss is: 0.5243 Accuracy is 69 %\n",
            "Completed training batch 14 Training Loss is: 0.4918 Validation Loss is: 0.5166 Accuracy is 69 %\n",
            "Completed training batch 15 Training Loss is: 0.4843 Validation Loss is: 0.5094 Accuracy is 69 %\n",
            "Completed training batch 16 Training Loss is: 0.4773 Validation Loss is: 0.5026 Accuracy is 69 %\n",
            "Completed training batch 17 Training Loss is: 0.4707 Validation Loss is: 0.4963 Accuracy is 69 %\n",
            "Completed training batch 18 Training Loss is: 0.4646 Validation Loss is: 0.4906 Accuracy is 69 %\n",
            "Completed training batch 19 Training Loss is: 0.4588 Validation Loss is: 0.4850 Accuracy is 69 %\n",
            "Completed training batch 20 Training Loss is: 0.4534 Validation Loss is: 0.4797 Accuracy is 69 %\n",
            "Completed training batch 21 Training Loss is: 0.4483 Validation Loss is: 0.4747 Accuracy is 69 %\n",
            "Completed training batch 22 Training Loss is: 0.4434 Validation Loss is: 0.4699 Accuracy is 69 %\n",
            "Completed training batch 23 Training Loss is: 0.4387 Validation Loss is: 0.4652 Accuracy is 69 %\n",
            "Completed training batch 24 Training Loss is: 0.4342 Validation Loss is: 0.4608 Accuracy is 69 %\n",
            "Completed training batch 25 Training Loss is: 0.4299 Validation Loss is: 0.4565 Accuracy is 69 %\n",
            "Completed training batch 26 Training Loss is: 0.4259 Validation Loss is: 0.4524 Accuracy is 69 %\n",
            "Completed training batch 27 Training Loss is: 0.4219 Validation Loss is: 0.4485 Accuracy is 69 %\n",
            "Completed training batch 28 Training Loss is: 0.4181 Validation Loss is: 0.4447 Accuracy is 69 %\n",
            "Completed training batch 29 Training Loss is: 0.4145 Validation Loss is: 0.4410 Accuracy is 72 %\n",
            "Completed training batch 30 Training Loss is: 0.4110 Validation Loss is: 0.4375 Accuracy is 75 %\n",
            "Completed training batch 31 Training Loss is: 0.4076 Validation Loss is: 0.4341 Accuracy is 75 %\n",
            "Completed training batch 32 Training Loss is: 0.4043 Validation Loss is: 0.4308 Accuracy is 75 %\n",
            "Completed training batch 33 Training Loss is: 0.4012 Validation Loss is: 0.4277 Accuracy is 77 %\n",
            "Completed training batch 34 Training Loss is: 0.3981 Validation Loss is: 0.4246 Accuracy is 77 %\n",
            "Completed training batch 35 Training Loss is: 0.3951 Validation Loss is: 0.4215 Accuracy is 77 %\n",
            "Completed training batch 36 Training Loss is: 0.3922 Validation Loss is: 0.4186 Accuracy is 80 %\n",
            "Completed training batch 37 Training Loss is: 0.3894 Validation Loss is: 0.4158 Accuracy is 83 %\n",
            "Completed training batch 38 Training Loss is: 0.3867 Validation Loss is: 0.4130 Accuracy is 83 %\n",
            "Completed training batch 39 Training Loss is: 0.3840 Validation Loss is: 0.4102 Accuracy is 83 %\n",
            "Completed training batch 40 Training Loss is: 0.3814 Validation Loss is: 0.4076 Accuracy is 83 %\n",
            "Completed training batch 41 Training Loss is: 0.3789 Validation Loss is: 0.4050 Accuracy is 83 %\n",
            "Completed training batch 42 Training Loss is: 0.3764 Validation Loss is: 0.4025 Accuracy is 86 %\n",
            "Completed training batch 43 Training Loss is: 0.3740 Validation Loss is: 0.4000 Accuracy is 86 %\n",
            "Completed training batch 44 Training Loss is: 0.3717 Validation Loss is: 0.3976 Accuracy is 86 %\n",
            "Completed training batch 45 Training Loss is: 0.3694 Validation Loss is: 0.3952 Accuracy is 86 %\n",
            "Completed training batch 46 Training Loss is: 0.3671 Validation Loss is: 0.3929 Accuracy is 86 %\n",
            "Completed training batch 47 Training Loss is: 0.3649 Validation Loss is: 0.3906 Accuracy is 88 %\n",
            "Completed training batch 48 Training Loss is: 0.3627 Validation Loss is: 0.3884 Accuracy is 88 %\n",
            "Completed training batch 49 Training Loss is: 0.3606 Validation Loss is: 0.3862 Accuracy is 88 %\n",
            "Completed training batch 50 Training Loss is: 0.3585 Validation Loss is: 0.3840 Accuracy is 88 %\n",
            "Completed training batch 51 Training Loss is: 0.3565 Validation Loss is: 0.3819 Accuracy is 88 %\n",
            "Completed training batch 52 Training Loss is: 0.3545 Validation Loss is: 0.3799 Accuracy is 88 %\n",
            "Completed training batch 53 Training Loss is: 0.3526 Validation Loss is: 0.3778 Accuracy is 88 %\n",
            "Completed training batch 54 Training Loss is: 0.3506 Validation Loss is: 0.3758 Accuracy is 88 %\n",
            "Completed training batch 55 Training Loss is: 0.3488 Validation Loss is: 0.3739 Accuracy is 88 %\n",
            "Completed training batch 56 Training Loss is: 0.3469 Validation Loss is: 0.3720 Accuracy is 88 %\n",
            "Completed training batch 57 Training Loss is: 0.3451 Validation Loss is: 0.3701 Accuracy is 94 %\n",
            "Completed training batch 58 Training Loss is: 0.3433 Validation Loss is: 0.3682 Accuracy is 94 %\n",
            "Completed training batch 59 Training Loss is: 0.3415 Validation Loss is: 0.3664 Accuracy is 94 %\n",
            "Completed training batch 60 Training Loss is: 0.3398 Validation Loss is: 0.3646 Accuracy is 94 %\n",
            "Completed training batch 61 Training Loss is: 0.3381 Validation Loss is: 0.3628 Accuracy is 94 %\n",
            "Completed training batch 62 Training Loss is: 0.3364 Validation Loss is: 0.3611 Accuracy is 94 %\n",
            "Completed training batch 63 Training Loss is: 0.3348 Validation Loss is: 0.3593 Accuracy is 94 %\n",
            "Completed training batch 64 Training Loss is: 0.3332 Validation Loss is: 0.3577 Accuracy is 94 %\n",
            "Completed training batch 65 Training Loss is: 0.3316 Validation Loss is: 0.3560 Accuracy is 94 %\n",
            "Completed training batch 66 Training Loss is: 0.3300 Validation Loss is: 0.3543 Accuracy is 94 %\n",
            "Completed training batch 67 Training Loss is: 0.3285 Validation Loss is: 0.3527 Accuracy is 94 %\n",
            "Completed training batch 68 Training Loss is: 0.3269 Validation Loss is: 0.3511 Accuracy is 94 %\n",
            "Completed training batch 69 Training Loss is: 0.3254 Validation Loss is: 0.3496 Accuracy is 94 %\n",
            "Completed training batch 70 Training Loss is: 0.3240 Validation Loss is: 0.3480 Accuracy is 94 %\n",
            "Completed training batch 71 Training Loss is: 0.3225 Validation Loss is: 0.3465 Accuracy is 94 %\n",
            "Completed training batch 72 Training Loss is: 0.3211 Validation Loss is: 0.3450 Accuracy is 94 %\n",
            "Completed training batch 73 Training Loss is: 0.3197 Validation Loss is: 0.3435 Accuracy is 94 %\n",
            "Completed training batch 74 Training Loss is: 0.3183 Validation Loss is: 0.3421 Accuracy is 94 %\n",
            "Completed training batch 75 Training Loss is: 0.3169 Validation Loss is: 0.3406 Accuracy is 94 %\n",
            "Completed training batch 76 Training Loss is: 0.3155 Validation Loss is: 0.3392 Accuracy is 97 %\n",
            "Completed training batch 77 Training Loss is: 0.3142 Validation Loss is: 0.3378 Accuracy is 97 %\n",
            "Completed training batch 78 Training Loss is: 0.3129 Validation Loss is: 0.3364 Accuracy is 97 %\n",
            "Completed training batch 79 Training Loss is: 0.3116 Validation Loss is: 0.3350 Accuracy is 97 %\n",
            "Completed training batch 80 Training Loss is: 0.3103 Validation Loss is: 0.3337 Accuracy is 97 %\n",
            "Completed training batch 81 Training Loss is: 0.3090 Validation Loss is: 0.3324 Accuracy is 97 %\n",
            "Completed training batch 82 Training Loss is: 0.3078 Validation Loss is: 0.3310 Accuracy is 97 %\n",
            "Completed training batch 83 Training Loss is: 0.3065 Validation Loss is: 0.3297 Accuracy is 97 %\n",
            "Completed training batch 84 Training Loss is: 0.3053 Validation Loss is: 0.3285 Accuracy is 97 %\n",
            "Completed training batch 85 Training Loss is: 0.3041 Validation Loss is: 0.3272 Accuracy is 97 %\n",
            "Completed training batch 86 Training Loss is: 0.3029 Validation Loss is: 0.3259 Accuracy is 97 %\n",
            "Completed training batch 87 Training Loss is: 0.3017 Validation Loss is: 0.3247 Accuracy is 97 %\n",
            "Completed training batch 88 Training Loss is: 0.3006 Validation Loss is: 0.3235 Accuracy is 97 %\n",
            "Completed training batch 89 Training Loss is: 0.2994 Validation Loss is: 0.3223 Accuracy is 97 %\n",
            "Completed training batch 90 Training Loss is: 0.2983 Validation Loss is: 0.3211 Accuracy is 97 %\n",
            "Completed training batch 91 Training Loss is: 0.2972 Validation Loss is: 0.3199 Accuracy is 97 %\n",
            "Completed training batch 92 Training Loss is: 0.2961 Validation Loss is: 0.3187 Accuracy is 97 %\n",
            "Completed training batch 93 Training Loss is: 0.2950 Validation Loss is: 0.3176 Accuracy is 97 %\n",
            "Completed training batch 94 Training Loss is: 0.2939 Validation Loss is: 0.3165 Accuracy is 97 %\n",
            "Completed training batch 95 Training Loss is: 0.2928 Validation Loss is: 0.3153 Accuracy is 97 %\n",
            "Completed training batch 96 Training Loss is: 0.2918 Validation Loss is: 0.3142 Accuracy is 97 %\n",
            "Completed training batch 97 Training Loss is: 0.2907 Validation Loss is: 0.3131 Accuracy is 97 %\n",
            "Completed training batch 98 Training Loss is: 0.2897 Validation Loss is: 0.3120 Accuracy is 97 %\n",
            "Completed training batch 99 Training Loss is: 0.2887 Validation Loss is: 0.3109 Accuracy is 97 %\n",
            "Completed training batch 100 Training Loss is: 0.2877 Validation Loss is: 0.3099 Accuracy is 97 %\n",
            "Completed training batch 101 Training Loss is: 0.2867 Validation Loss is: 0.3088 Accuracy is 97 %\n",
            "Completed training batch 102 Training Loss is: 0.2857 Validation Loss is: 0.3078 Accuracy is 97 %\n",
            "Completed training batch 103 Training Loss is: 0.2847 Validation Loss is: 0.3068 Accuracy is 97 %\n",
            "Completed training batch 104 Training Loss is: 0.2838 Validation Loss is: 0.3057 Accuracy is 97 %\n",
            "Completed training batch 105 Training Loss is: 0.2828 Validation Loss is: 0.3047 Accuracy is 97 %\n",
            "Completed training batch 106 Training Loss is: 0.2819 Validation Loss is: 0.3037 Accuracy is 97 %\n",
            "Completed training batch 107 Training Loss is: 0.2809 Validation Loss is: 0.3027 Accuracy is 97 %\n",
            "Completed training batch 108 Training Loss is: 0.2800 Validation Loss is: 0.3018 Accuracy is 97 %\n",
            "Completed training batch 109 Training Loss is: 0.2791 Validation Loss is: 0.3008 Accuracy is 97 %\n",
            "Completed training batch 110 Training Loss is: 0.2782 Validation Loss is: 0.2998 Accuracy is 97 %\n",
            "Completed training batch 111 Training Loss is: 0.2773 Validation Loss is: 0.2989 Accuracy is 97 %\n",
            "Completed training batch 112 Training Loss is: 0.2764 Validation Loss is: 0.2979 Accuracy is 97 %\n",
            "Completed training batch 113 Training Loss is: 0.2755 Validation Loss is: 0.2970 Accuracy is 97 %\n",
            "Completed training batch 114 Training Loss is: 0.2746 Validation Loss is: 0.2961 Accuracy is 97 %\n",
            "Completed training batch 115 Training Loss is: 0.2738 Validation Loss is: 0.2952 Accuracy is 97 %\n",
            "Completed training batch 116 Training Loss is: 0.2729 Validation Loss is: 0.2943 Accuracy is 97 %\n",
            "Completed training batch 117 Training Loss is: 0.2721 Validation Loss is: 0.2934 Accuracy is 97 %\n",
            "Completed training batch 118 Training Loss is: 0.2712 Validation Loss is: 0.2925 Accuracy is 97 %\n",
            "Completed training batch 119 Training Loss is: 0.2704 Validation Loss is: 0.2916 Accuracy is 97 %\n",
            "Completed training batch 120 Training Loss is: 0.2696 Validation Loss is: 0.2908 Accuracy is 97 %\n",
            "Completed training batch 121 Training Loss is: 0.2688 Validation Loss is: 0.2899 Accuracy is 97 %\n",
            "Completed training batch 122 Training Loss is: 0.2680 Validation Loss is: 0.2890 Accuracy is 97 %\n",
            "Completed training batch 123 Training Loss is: 0.2672 Validation Loss is: 0.2882 Accuracy is 97 %\n",
            "Completed training batch 124 Training Loss is: 0.2664 Validation Loss is: 0.2874 Accuracy is 97 %\n",
            "Completed training batch 125 Training Loss is: 0.2656 Validation Loss is: 0.2865 Accuracy is 97 %\n",
            "Completed training batch 126 Training Loss is: 0.2648 Validation Loss is: 0.2857 Accuracy is 97 %\n",
            "Completed training batch 127 Training Loss is: 0.2641 Validation Loss is: 0.2849 Accuracy is 97 %\n",
            "Completed training batch 128 Training Loss is: 0.2633 Validation Loss is: 0.2841 Accuracy is 97 %\n",
            "Completed training batch 129 Training Loss is: 0.2626 Validation Loss is: 0.2833 Accuracy is 97 %\n",
            "Completed training batch 130 Training Loss is: 0.2618 Validation Loss is: 0.2825 Accuracy is 97 %\n",
            "Completed training batch 131 Training Loss is: 0.2611 Validation Loss is: 0.2817 Accuracy is 97 %\n",
            "Completed training batch 132 Training Loss is: 0.2603 Validation Loss is: 0.2810 Accuracy is 97 %\n",
            "Completed training batch 133 Training Loss is: 0.2596 Validation Loss is: 0.2802 Accuracy is 97 %\n",
            "Completed training batch 134 Training Loss is: 0.2589 Validation Loss is: 0.2794 Accuracy is 97 %\n",
            "Completed training batch 135 Training Loss is: 0.2582 Validation Loss is: 0.2787 Accuracy is 97 %\n",
            "Completed training batch 136 Training Loss is: 0.2575 Validation Loss is: 0.2779 Accuracy is 97 %\n",
            "Completed training batch 137 Training Loss is: 0.2568 Validation Loss is: 0.2772 Accuracy is 97 %\n",
            "Completed training batch 138 Training Loss is: 0.2561 Validation Loss is: 0.2764 Accuracy is 97 %\n",
            "Completed training batch 139 Training Loss is: 0.2554 Validation Loss is: 0.2757 Accuracy is 97 %\n",
            "Completed training batch 140 Training Loss is: 0.2547 Validation Loss is: 0.2750 Accuracy is 97 %\n",
            "Completed training batch 141 Training Loss is: 0.2540 Validation Loss is: 0.2743 Accuracy is 97 %\n",
            "Completed training batch 142 Training Loss is: 0.2534 Validation Loss is: 0.2735 Accuracy is 97 %\n",
            "Completed training batch 143 Training Loss is: 0.2527 Validation Loss is: 0.2728 Accuracy is 97 %\n",
            "Completed training batch 144 Training Loss is: 0.2520 Validation Loss is: 0.2721 Accuracy is 97 %\n",
            "Completed training batch 145 Training Loss is: 0.2514 Validation Loss is: 0.2714 Accuracy is 97 %\n",
            "Completed training batch 146 Training Loss is: 0.2507 Validation Loss is: 0.2707 Accuracy is 97 %\n",
            "Completed training batch 147 Training Loss is: 0.2501 Validation Loss is: 0.2701 Accuracy is 97 %\n",
            "Completed training batch 148 Training Loss is: 0.2494 Validation Loss is: 0.2694 Accuracy is 97 %\n",
            "Completed training batch 149 Training Loss is: 0.2488 Validation Loss is: 0.2687 Accuracy is 97 %\n",
            "Completed training batch 150 Training Loss is: 0.2482 Validation Loss is: 0.2680 Accuracy is 97 %\n",
            "Completed training batch 151 Training Loss is: 0.2476 Validation Loss is: 0.2674 Accuracy is 97 %\n",
            "Completed training batch 152 Training Loss is: 0.2469 Validation Loss is: 0.2667 Accuracy is 97 %\n",
            "Completed training batch 153 Training Loss is: 0.2463 Validation Loss is: 0.2661 Accuracy is 97 %\n",
            "Completed training batch 154 Training Loss is: 0.2457 Validation Loss is: 0.2654 Accuracy is 97 %\n",
            "Completed training batch 155 Training Loss is: 0.2451 Validation Loss is: 0.2648 Accuracy is 97 %\n",
            "Completed training batch 156 Training Loss is: 0.2445 Validation Loss is: 0.2641 Accuracy is 97 %\n",
            "Completed training batch 157 Training Loss is: 0.2439 Validation Loss is: 0.2635 Accuracy is 97 %\n",
            "Completed training batch 158 Training Loss is: 0.2433 Validation Loss is: 0.2629 Accuracy is 97 %\n",
            "Completed training batch 159 Training Loss is: 0.2428 Validation Loss is: 0.2623 Accuracy is 97 %\n",
            "Completed training batch 160 Training Loss is: 0.2422 Validation Loss is: 0.2616 Accuracy is 97 %\n",
            "Completed training batch 161 Training Loss is: 0.2416 Validation Loss is: 0.2610 Accuracy is 97 %\n",
            "Completed training batch 162 Training Loss is: 0.2410 Validation Loss is: 0.2604 Accuracy is 97 %\n",
            "Completed training batch 163 Training Loss is: 0.2405 Validation Loss is: 0.2598 Accuracy is 97 %\n",
            "Completed training batch 164 Training Loss is: 0.2399 Validation Loss is: 0.2592 Accuracy is 97 %\n",
            "Completed training batch 165 Training Loss is: 0.2393 Validation Loss is: 0.2586 Accuracy is 97 %\n",
            "Completed training batch 166 Training Loss is: 0.2388 Validation Loss is: 0.2580 Accuracy is 97 %\n",
            "Completed training batch 167 Training Loss is: 0.2382 Validation Loss is: 0.2574 Accuracy is 97 %\n",
            "Completed training batch 168 Training Loss is: 0.2377 Validation Loss is: 0.2569 Accuracy is 97 %\n",
            "Completed training batch 169 Training Loss is: 0.2371 Validation Loss is: 0.2563 Accuracy is 97 %\n",
            "Completed training batch 170 Training Loss is: 0.2366 Validation Loss is: 0.2557 Accuracy is 97 %\n",
            "Completed training batch 171 Training Loss is: 0.2361 Validation Loss is: 0.2551 Accuracy is 97 %\n",
            "Completed training batch 172 Training Loss is: 0.2355 Validation Loss is: 0.2546 Accuracy is 97 %\n",
            "Completed training batch 173 Training Loss is: 0.2350 Validation Loss is: 0.2540 Accuracy is 97 %\n",
            "Completed training batch 174 Training Loss is: 0.2345 Validation Loss is: 0.2535 Accuracy is 97 %\n",
            "Completed training batch 175 Training Loss is: 0.2340 Validation Loss is: 0.2529 Accuracy is 97 %\n",
            "Completed training batch 176 Training Loss is: 0.2335 Validation Loss is: 0.2524 Accuracy is 97 %\n",
            "Completed training batch 177 Training Loss is: 0.2330 Validation Loss is: 0.2518 Accuracy is 97 %\n",
            "Completed training batch 178 Training Loss is: 0.2324 Validation Loss is: 0.2513 Accuracy is 97 %\n",
            "Completed training batch 179 Training Loss is: 0.2319 Validation Loss is: 0.2508 Accuracy is 97 %\n",
            "Completed training batch 180 Training Loss is: 0.2314 Validation Loss is: 0.2502 Accuracy is 97 %\n",
            "Completed training batch 181 Training Loss is: 0.2309 Validation Loss is: 0.2497 Accuracy is 97 %\n",
            "Completed training batch 182 Training Loss is: 0.2305 Validation Loss is: 0.2492 Accuracy is 97 %\n",
            "Completed training batch 183 Training Loss is: 0.2300 Validation Loss is: 0.2486 Accuracy is 97 %\n",
            "Completed training batch 184 Training Loss is: 0.2295 Validation Loss is: 0.2481 Accuracy is 97 %\n",
            "Completed training batch 185 Training Loss is: 0.2290 Validation Loss is: 0.2476 Accuracy is 97 %\n",
            "Completed training batch 186 Training Loss is: 0.2285 Validation Loss is: 0.2471 Accuracy is 97 %\n",
            "Completed training batch 187 Training Loss is: 0.2280 Validation Loss is: 0.2466 Accuracy is 97 %\n",
            "Completed training batch 188 Training Loss is: 0.2276 Validation Loss is: 0.2461 Accuracy is 97 %\n",
            "Completed training batch 189 Training Loss is: 0.2271 Validation Loss is: 0.2456 Accuracy is 97 %\n",
            "Completed training batch 190 Training Loss is: 0.2266 Validation Loss is: 0.2451 Accuracy is 97 %\n",
            "Completed training batch 191 Training Loss is: 0.2262 Validation Loss is: 0.2446 Accuracy is 97 %\n",
            "Completed training batch 192 Training Loss is: 0.2257 Validation Loss is: 0.2441 Accuracy is 97 %\n",
            "Completed training batch 193 Training Loss is: 0.2252 Validation Loss is: 0.2436 Accuracy is 97 %\n",
            "Completed training batch 194 Training Loss is: 0.2248 Validation Loss is: 0.2431 Accuracy is 97 %\n",
            "Completed training batch 195 Training Loss is: 0.2243 Validation Loss is: 0.2426 Accuracy is 97 %\n",
            "Completed training batch 196 Training Loss is: 0.2239 Validation Loss is: 0.2422 Accuracy is 97 %\n",
            "Completed training batch 197 Training Loss is: 0.2234 Validation Loss is: 0.2417 Accuracy is 97 %\n",
            "Completed training batch 198 Training Loss is: 0.2230 Validation Loss is: 0.2412 Accuracy is 97 %\n",
            "Completed training batch 199 Training Loss is: 0.2226 Validation Loss is: 0.2407 Accuracy is 97 %\n",
            "Completed training batch 200 Training Loss is: 0.2221 Validation Loss is: 0.2403 Accuracy is 97 %\n",
            "Completed training batch 201 Training Loss is: 0.2217 Validation Loss is: 0.2398 Accuracy is 97 %\n",
            "Completed training batch 202 Training Loss is: 0.2213 Validation Loss is: 0.2394 Accuracy is 97 %\n",
            "Completed training batch 203 Training Loss is: 0.2208 Validation Loss is: 0.2389 Accuracy is 97 %\n",
            "Completed training batch 204 Training Loss is: 0.2204 Validation Loss is: 0.2384 Accuracy is 97 %\n",
            "Completed training batch 205 Training Loss is: 0.2200 Validation Loss is: 0.2380 Accuracy is 97 %\n",
            "Completed training batch 206 Training Loss is: 0.2196 Validation Loss is: 0.2375 Accuracy is 97 %\n",
            "Completed training batch 207 Training Loss is: 0.2191 Validation Loss is: 0.2371 Accuracy is 97 %\n",
            "Completed training batch 208 Training Loss is: 0.2187 Validation Loss is: 0.2367 Accuracy is 97 %\n",
            "Completed training batch 209 Training Loss is: 0.2183 Validation Loss is: 0.2362 Accuracy is 97 %\n",
            "Completed training batch 210 Training Loss is: 0.2179 Validation Loss is: 0.2358 Accuracy is 97 %\n",
            "Completed training batch 211 Training Loss is: 0.2175 Validation Loss is: 0.2353 Accuracy is 97 %\n",
            "Completed training batch 212 Training Loss is: 0.2171 Validation Loss is: 0.2349 Accuracy is 97 %\n",
            "Completed training batch 213 Training Loss is: 0.2167 Validation Loss is: 0.2345 Accuracy is 97 %\n",
            "Completed training batch 214 Training Loss is: 0.2163 Validation Loss is: 0.2340 Accuracy is 97 %\n",
            "Completed training batch 215 Training Loss is: 0.2159 Validation Loss is: 0.2336 Accuracy is 97 %\n",
            "Completed training batch 216 Training Loss is: 0.2155 Validation Loss is: 0.2332 Accuracy is 97 %\n",
            "Completed training batch 217 Training Loss is: 0.2151 Validation Loss is: 0.2328 Accuracy is 97 %\n",
            "Completed training batch 218 Training Loss is: 0.2147 Validation Loss is: 0.2324 Accuracy is 97 %\n",
            "Completed training batch 219 Training Loss is: 0.2143 Validation Loss is: 0.2319 Accuracy is 97 %\n",
            "Completed training batch 220 Training Loss is: 0.2139 Validation Loss is: 0.2315 Accuracy is 97 %\n",
            "Completed training batch 221 Training Loss is: 0.2136 Validation Loss is: 0.2311 Accuracy is 97 %\n",
            "Completed training batch 222 Training Loss is: 0.2132 Validation Loss is: 0.2307 Accuracy is 97 %\n",
            "Completed training batch 223 Training Loss is: 0.2128 Validation Loss is: 0.2303 Accuracy is 97 %\n",
            "Completed training batch 224 Training Loss is: 0.2124 Validation Loss is: 0.2299 Accuracy is 97 %\n",
            "Completed training batch 225 Training Loss is: 0.2120 Validation Loss is: 0.2295 Accuracy is 97 %\n",
            "Completed training batch 226 Training Loss is: 0.2117 Validation Loss is: 0.2291 Accuracy is 97 %\n",
            "Completed training batch 227 Training Loss is: 0.2113 Validation Loss is: 0.2287 Accuracy is 97 %\n",
            "Completed training batch 228 Training Loss is: 0.2109 Validation Loss is: 0.2283 Accuracy is 97 %\n",
            "Completed training batch 229 Training Loss is: 0.2106 Validation Loss is: 0.2279 Accuracy is 97 %\n",
            "Completed training batch 230 Training Loss is: 0.2102 Validation Loss is: 0.2275 Accuracy is 97 %\n",
            "Completed training batch 231 Training Loss is: 0.2098 Validation Loss is: 0.2271 Accuracy is 97 %\n",
            "Completed training batch 232 Training Loss is: 0.2095 Validation Loss is: 0.2268 Accuracy is 97 %\n",
            "Completed training batch 233 Training Loss is: 0.2091 Validation Loss is: 0.2264 Accuracy is 97 %\n",
            "Completed training batch 234 Training Loss is: 0.2088 Validation Loss is: 0.2260 Accuracy is 97 %\n",
            "Completed training batch 235 Training Loss is: 0.2084 Validation Loss is: 0.2256 Accuracy is 97 %\n",
            "Completed training batch 236 Training Loss is: 0.2081 Validation Loss is: 0.2252 Accuracy is 97 %\n",
            "Completed training batch 237 Training Loss is: 0.2077 Validation Loss is: 0.2249 Accuracy is 97 %\n",
            "Completed training batch 238 Training Loss is: 0.2074 Validation Loss is: 0.2245 Accuracy is 97 %\n",
            "Completed training batch 239 Training Loss is: 0.2070 Validation Loss is: 0.2241 Accuracy is 97 %\n",
            "Completed training batch 240 Training Loss is: 0.2067 Validation Loss is: 0.2238 Accuracy is 97 %\n",
            "Completed training batch 241 Training Loss is: 0.2063 Validation Loss is: 0.2234 Accuracy is 97 %\n",
            "Completed training batch 242 Training Loss is: 0.2060 Validation Loss is: 0.2230 Accuracy is 97 %\n",
            "Completed training batch 243 Training Loss is: 0.2057 Validation Loss is: 0.2227 Accuracy is 97 %\n",
            "Completed training batch 244 Training Loss is: 0.2053 Validation Loss is: 0.2223 Accuracy is 97 %\n",
            "Completed training batch 245 Training Loss is: 0.2050 Validation Loss is: 0.2219 Accuracy is 97 %\n",
            "Completed training batch 246 Training Loss is: 0.2047 Validation Loss is: 0.2216 Accuracy is 97 %\n",
            "Completed training batch 247 Training Loss is: 0.2043 Validation Loss is: 0.2212 Accuracy is 97 %\n",
            "Completed training batch 248 Training Loss is: 0.2040 Validation Loss is: 0.2209 Accuracy is 97 %\n",
            "Completed training batch 249 Training Loss is: 0.2037 Validation Loss is: 0.2205 Accuracy is 97 %\n",
            "Completed training batch 250 Training Loss is: 0.2033 Validation Loss is: 0.2202 Accuracy is 97 %\n",
            "Completed training batch 251 Training Loss is: 0.2030 Validation Loss is: 0.2198 Accuracy is 97 %\n",
            "Completed training batch 252 Training Loss is: 0.2027 Validation Loss is: 0.2195 Accuracy is 97 %\n",
            "Completed training batch 253 Training Loss is: 0.2024 Validation Loss is: 0.2191 Accuracy is 97 %\n",
            "Completed training batch 254 Training Loss is: 0.2021 Validation Loss is: 0.2188 Accuracy is 97 %\n",
            "Completed training batch 255 Training Loss is: 0.2017 Validation Loss is: 0.2185 Accuracy is 97 %\n",
            "Completed training batch 256 Training Loss is: 0.2014 Validation Loss is: 0.2181 Accuracy is 97 %\n",
            "Completed training batch 257 Training Loss is: 0.2011 Validation Loss is: 0.2178 Accuracy is 97 %\n",
            "Completed training batch 258 Training Loss is: 0.2008 Validation Loss is: 0.2174 Accuracy is 97 %\n",
            "Completed training batch 259 Training Loss is: 0.2005 Validation Loss is: 0.2171 Accuracy is 97 %\n",
            "Completed training batch 260 Training Loss is: 0.2002 Validation Loss is: 0.2168 Accuracy is 97 %\n",
            "Completed training batch 261 Training Loss is: 0.1999 Validation Loss is: 0.2165 Accuracy is 97 %\n",
            "Completed training batch 262 Training Loss is: 0.1996 Validation Loss is: 0.2161 Accuracy is 97 %\n",
            "Completed training batch 263 Training Loss is: 0.1993 Validation Loss is: 0.2158 Accuracy is 97 %\n",
            "Completed training batch 264 Training Loss is: 0.1990 Validation Loss is: 0.2155 Accuracy is 97 %\n",
            "Completed training batch 265 Training Loss is: 0.1987 Validation Loss is: 0.2152 Accuracy is 97 %\n",
            "Completed training batch 266 Training Loss is: 0.1984 Validation Loss is: 0.2148 Accuracy is 97 %\n",
            "Completed training batch 267 Training Loss is: 0.1981 Validation Loss is: 0.2145 Accuracy is 97 %\n",
            "Completed training batch 268 Training Loss is: 0.1978 Validation Loss is: 0.2142 Accuracy is 97 %\n",
            "Completed training batch 269 Training Loss is: 0.1975 Validation Loss is: 0.2139 Accuracy is 97 %\n",
            "Completed training batch 270 Training Loss is: 0.1972 Validation Loss is: 0.2136 Accuracy is 97 %\n",
            "Completed training batch 271 Training Loss is: 0.1969 Validation Loss is: 0.2133 Accuracy is 97 %\n",
            "Completed training batch 272 Training Loss is: 0.1966 Validation Loss is: 0.2129 Accuracy is 97 %\n",
            "Completed training batch 273 Training Loss is: 0.1963 Validation Loss is: 0.2126 Accuracy is 97 %\n",
            "Completed training batch 274 Training Loss is: 0.1960 Validation Loss is: 0.2123 Accuracy is 97 %\n",
            "Completed training batch 275 Training Loss is: 0.1957 Validation Loss is: 0.2120 Accuracy is 97 %\n",
            "Completed training batch 276 Training Loss is: 0.1954 Validation Loss is: 0.2117 Accuracy is 97 %\n",
            "Completed training batch 277 Training Loss is: 0.1952 Validation Loss is: 0.2114 Accuracy is 97 %\n",
            "Completed training batch 278 Training Loss is: 0.1949 Validation Loss is: 0.2111 Accuracy is 97 %\n",
            "Completed training batch 279 Training Loss is: 0.1946 Validation Loss is: 0.2108 Accuracy is 97 %\n",
            "Completed training batch 280 Training Loss is: 0.1943 Validation Loss is: 0.2105 Accuracy is 97 %\n",
            "Completed training batch 281 Training Loss is: 0.1940 Validation Loss is: 0.2102 Accuracy is 97 %\n",
            "Completed training batch 282 Training Loss is: 0.1938 Validation Loss is: 0.2099 Accuracy is 97 %\n",
            "Completed training batch 283 Training Loss is: 0.1935 Validation Loss is: 0.2096 Accuracy is 97 %\n",
            "Completed training batch 284 Training Loss is: 0.1932 Validation Loss is: 0.2093 Accuracy is 97 %\n",
            "Completed training batch 285 Training Loss is: 0.1929 Validation Loss is: 0.2090 Accuracy is 97 %\n",
            "Completed training batch 286 Training Loss is: 0.1927 Validation Loss is: 0.2087 Accuracy is 97 %\n",
            "Completed training batch 287 Training Loss is: 0.1924 Validation Loss is: 0.2085 Accuracy is 97 %\n",
            "Completed training batch 288 Training Loss is: 0.1921 Validation Loss is: 0.2082 Accuracy is 97 %\n",
            "Completed training batch 289 Training Loss is: 0.1919 Validation Loss is: 0.2079 Accuracy is 97 %\n",
            "Completed training batch 290 Training Loss is: 0.1916 Validation Loss is: 0.2076 Accuracy is 97 %\n",
            "Completed training batch 291 Training Loss is: 0.1913 Validation Loss is: 0.2073 Accuracy is 97 %\n",
            "Completed training batch 292 Training Loss is: 0.1911 Validation Loss is: 0.2070 Accuracy is 97 %\n",
            "Completed training batch 293 Training Loss is: 0.1908 Validation Loss is: 0.2067 Accuracy is 97 %\n",
            "Completed training batch 294 Training Loss is: 0.1905 Validation Loss is: 0.2065 Accuracy is 97 %\n",
            "Completed training batch 295 Training Loss is: 0.1903 Validation Loss is: 0.2062 Accuracy is 97 %\n",
            "Completed training batch 296 Training Loss is: 0.1900 Validation Loss is: 0.2059 Accuracy is 97 %\n",
            "Completed training batch 297 Training Loss is: 0.1898 Validation Loss is: 0.2056 Accuracy is 97 %\n",
            "Completed training batch 298 Training Loss is: 0.1895 Validation Loss is: 0.2054 Accuracy is 97 %\n",
            "Completed training batch 299 Training Loss is: 0.1893 Validation Loss is: 0.2051 Accuracy is 97 %\n",
            "Completed training batch 300 Training Loss is: 0.1890 Validation Loss is: 0.2048 Accuracy is 97 %\n",
            "Completed training batch 301 Training Loss is: 0.1887 Validation Loss is: 0.2045 Accuracy is 97 %\n",
            "Completed training batch 302 Training Loss is: 0.1885 Validation Loss is: 0.2043 Accuracy is 97 %\n",
            "Completed training batch 303 Training Loss is: 0.1882 Validation Loss is: 0.2040 Accuracy is 97 %\n",
            "Completed training batch 304 Training Loss is: 0.1880 Validation Loss is: 0.2037 Accuracy is 97 %\n",
            "Completed training batch 305 Training Loss is: 0.1877 Validation Loss is: 0.2035 Accuracy is 97 %\n",
            "Completed training batch 306 Training Loss is: 0.1875 Validation Loss is: 0.2032 Accuracy is 97 %\n",
            "Completed training batch 307 Training Loss is: 0.1873 Validation Loss is: 0.2029 Accuracy is 97 %\n",
            "Completed training batch 308 Training Loss is: 0.1870 Validation Loss is: 0.2027 Accuracy is 97 %\n",
            "Completed training batch 309 Training Loss is: 0.1868 Validation Loss is: 0.2024 Accuracy is 97 %\n",
            "Completed training batch 310 Training Loss is: 0.1865 Validation Loss is: 0.2022 Accuracy is 97 %\n",
            "Completed training batch 311 Training Loss is: 0.1863 Validation Loss is: 0.2019 Accuracy is 97 %\n",
            "Completed training batch 312 Training Loss is: 0.1860 Validation Loss is: 0.2016 Accuracy is 97 %\n",
            "Completed training batch 313 Training Loss is: 0.1858 Validation Loss is: 0.2014 Accuracy is 97 %\n",
            "Completed training batch 314 Training Loss is: 0.1856 Validation Loss is: 0.2011 Accuracy is 97 %\n",
            "Completed training batch 315 Training Loss is: 0.1853 Validation Loss is: 0.2009 Accuracy is 97 %\n",
            "Completed training batch 316 Training Loss is: 0.1851 Validation Loss is: 0.2006 Accuracy is 97 %\n",
            "Completed training batch 317 Training Loss is: 0.1849 Validation Loss is: 0.2004 Accuracy is 97 %\n",
            "Completed training batch 318 Training Loss is: 0.1846 Validation Loss is: 0.2001 Accuracy is 97 %\n",
            "Completed training batch 319 Training Loss is: 0.1844 Validation Loss is: 0.1999 Accuracy is 97 %\n",
            "Completed training batch 320 Training Loss is: 0.1841 Validation Loss is: 0.1996 Accuracy is 97 %\n",
            "Completed training batch 321 Training Loss is: 0.1839 Validation Loss is: 0.1994 Accuracy is 97 %\n",
            "Completed training batch 322 Training Loss is: 0.1837 Validation Loss is: 0.1991 Accuracy is 97 %\n",
            "Completed training batch 323 Training Loss is: 0.1835 Validation Loss is: 0.1989 Accuracy is 97 %\n",
            "Completed training batch 324 Training Loss is: 0.1832 Validation Loss is: 0.1986 Accuracy is 97 %\n",
            "Completed training batch 325 Training Loss is: 0.1830 Validation Loss is: 0.1984 Accuracy is 97 %\n",
            "Completed training batch 326 Training Loss is: 0.1828 Validation Loss is: 0.1982 Accuracy is 97 %\n",
            "Completed training batch 327 Training Loss is: 0.1826 Validation Loss is: 0.1979 Accuracy is 97 %\n",
            "Completed training batch 328 Training Loss is: 0.1823 Validation Loss is: 0.1977 Accuracy is 97 %\n",
            "Completed training batch 329 Training Loss is: 0.1821 Validation Loss is: 0.1974 Accuracy is 97 %\n",
            "Completed training batch 330 Training Loss is: 0.1819 Validation Loss is: 0.1972 Accuracy is 97 %\n",
            "Completed training batch 331 Training Loss is: 0.1817 Validation Loss is: 0.1970 Accuracy is 97 %\n",
            "Completed training batch 332 Training Loss is: 0.1814 Validation Loss is: 0.1967 Accuracy is 97 %\n",
            "Completed training batch 333 Training Loss is: 0.1812 Validation Loss is: 0.1965 Accuracy is 97 %\n",
            "Completed training batch 334 Training Loss is: 0.1810 Validation Loss is: 0.1963 Accuracy is 97 %\n",
            "Completed training batch 335 Training Loss is: 0.1808 Validation Loss is: 0.1960 Accuracy is 97 %\n",
            "Completed training batch 336 Training Loss is: 0.1806 Validation Loss is: 0.1958 Accuracy is 97 %\n",
            "Completed training batch 337 Training Loss is: 0.1803 Validation Loss is: 0.1956 Accuracy is 97 %\n",
            "Completed training batch 338 Training Loss is: 0.1801 Validation Loss is: 0.1953 Accuracy is 97 %\n",
            "Completed training batch 339 Training Loss is: 0.1799 Validation Loss is: 0.1951 Accuracy is 97 %\n",
            "Completed training batch 340 Training Loss is: 0.1797 Validation Loss is: 0.1949 Accuracy is 97 %\n",
            "Completed training batch 341 Training Loss is: 0.1795 Validation Loss is: 0.1946 Accuracy is 97 %\n",
            "Completed training batch 342 Training Loss is: 0.1793 Validation Loss is: 0.1944 Accuracy is 97 %\n",
            "Completed training batch 343 Training Loss is: 0.1791 Validation Loss is: 0.1942 Accuracy is 97 %\n",
            "Completed training batch 344 Training Loss is: 0.1789 Validation Loss is: 0.1940 Accuracy is 97 %\n",
            "Completed training batch 345 Training Loss is: 0.1786 Validation Loss is: 0.1937 Accuracy is 97 %\n",
            "Completed training batch 346 Training Loss is: 0.1784 Validation Loss is: 0.1935 Accuracy is 97 %\n",
            "Completed training batch 347 Training Loss is: 0.1782 Validation Loss is: 0.1933 Accuracy is 97 %\n",
            "Completed training batch 348 Training Loss is: 0.1780 Validation Loss is: 0.1931 Accuracy is 97 %\n",
            "Completed training batch 349 Training Loss is: 0.1778 Validation Loss is: 0.1929 Accuracy is 97 %\n",
            "Completed training batch 350 Training Loss is: 0.1776 Validation Loss is: 0.1926 Accuracy is 97 %\n",
            "Completed training batch 351 Training Loss is: 0.1774 Validation Loss is: 0.1924 Accuracy is 97 %\n",
            "Completed training batch 352 Training Loss is: 0.1772 Validation Loss is: 0.1922 Accuracy is 97 %\n",
            "Completed training batch 353 Training Loss is: 0.1770 Validation Loss is: 0.1920 Accuracy is 97 %\n",
            "Completed training batch 354 Training Loss is: 0.1768 Validation Loss is: 0.1918 Accuracy is 97 %\n",
            "Completed training batch 355 Training Loss is: 0.1766 Validation Loss is: 0.1916 Accuracy is 97 %\n",
            "Completed training batch 356 Training Loss is: 0.1764 Validation Loss is: 0.1913 Accuracy is 97 %\n",
            "Completed training batch 357 Training Loss is: 0.1762 Validation Loss is: 0.1911 Accuracy is 97 %\n",
            "Completed training batch 358 Training Loss is: 0.1760 Validation Loss is: 0.1909 Accuracy is 97 %\n",
            "Completed training batch 359 Training Loss is: 0.1758 Validation Loss is: 0.1907 Accuracy is 97 %\n",
            "Completed training batch 360 Training Loss is: 0.1756 Validation Loss is: 0.1905 Accuracy is 97 %\n",
            "Completed training batch 361 Training Loss is: 0.1754 Validation Loss is: 0.1903 Accuracy is 97 %\n",
            "Completed training batch 362 Training Loss is: 0.1752 Validation Loss is: 0.1901 Accuracy is 97 %\n",
            "Completed training batch 363 Training Loss is: 0.1750 Validation Loss is: 0.1899 Accuracy is 97 %\n",
            "Completed training batch 364 Training Loss is: 0.1748 Validation Loss is: 0.1897 Accuracy is 97 %\n",
            "Completed training batch 365 Training Loss is: 0.1746 Validation Loss is: 0.1895 Accuracy is 97 %\n",
            "Completed training batch 366 Training Loss is: 0.1744 Validation Loss is: 0.1893 Accuracy is 97 %\n",
            "Completed training batch 367 Training Loss is: 0.1743 Validation Loss is: 0.1890 Accuracy is 97 %\n",
            "Completed training batch 368 Training Loss is: 0.1741 Validation Loss is: 0.1888 Accuracy is 97 %\n",
            "Completed training batch 369 Training Loss is: 0.1739 Validation Loss is: 0.1886 Accuracy is 97 %\n",
            "Completed training batch 370 Training Loss is: 0.1737 Validation Loss is: 0.1884 Accuracy is 97 %\n",
            "Completed training batch 371 Training Loss is: 0.1735 Validation Loss is: 0.1882 Accuracy is 97 %\n",
            "Completed training batch 372 Training Loss is: 0.1733 Validation Loss is: 0.1880 Accuracy is 97 %\n",
            "Completed training batch 373 Training Loss is: 0.1731 Validation Loss is: 0.1878 Accuracy is 97 %\n",
            "Completed training batch 374 Training Loss is: 0.1729 Validation Loss is: 0.1876 Accuracy is 97 %\n",
            "Completed training batch 375 Training Loss is: 0.1727 Validation Loss is: 0.1874 Accuracy is 97 %\n",
            "Completed training batch 376 Training Loss is: 0.1726 Validation Loss is: 0.1872 Accuracy is 97 %\n",
            "Completed training batch 377 Training Loss is: 0.1724 Validation Loss is: 0.1870 Accuracy is 97 %\n",
            "Completed training batch 378 Training Loss is: 0.1722 Validation Loss is: 0.1868 Accuracy is 97 %\n",
            "Completed training batch 379 Training Loss is: 0.1720 Validation Loss is: 0.1867 Accuracy is 97 %\n",
            "Completed training batch 380 Training Loss is: 0.1718 Validation Loss is: 0.1865 Accuracy is 97 %\n",
            "Completed training batch 381 Training Loss is: 0.1716 Validation Loss is: 0.1863 Accuracy is 97 %\n",
            "Completed training batch 382 Training Loss is: 0.1715 Validation Loss is: 0.1861 Accuracy is 97 %\n",
            "Completed training batch 383 Training Loss is: 0.1713 Validation Loss is: 0.1859 Accuracy is 97 %\n",
            "Completed training batch 384 Training Loss is: 0.1711 Validation Loss is: 0.1857 Accuracy is 97 %\n",
            "Completed training batch 385 Training Loss is: 0.1709 Validation Loss is: 0.1855 Accuracy is 97 %\n",
            "Completed training batch 386 Training Loss is: 0.1707 Validation Loss is: 0.1853 Accuracy is 97 %\n",
            "Completed training batch 387 Training Loss is: 0.1706 Validation Loss is: 0.1851 Accuracy is 97 %\n",
            "Completed training batch 388 Training Loss is: 0.1704 Validation Loss is: 0.1849 Accuracy is 97 %\n",
            "Completed training batch 389 Training Loss is: 0.1702 Validation Loss is: 0.1847 Accuracy is 97 %\n",
            "Completed training batch 390 Training Loss is: 0.1700 Validation Loss is: 0.1845 Accuracy is 97 %\n",
            "Completed training batch 391 Training Loss is: 0.1699 Validation Loss is: 0.1844 Accuracy is 97 %\n",
            "Completed training batch 392 Training Loss is: 0.1697 Validation Loss is: 0.1842 Accuracy is 97 %\n",
            "Completed training batch 393 Training Loss is: 0.1695 Validation Loss is: 0.1840 Accuracy is 97 %\n",
            "Completed training batch 394 Training Loss is: 0.1693 Validation Loss is: 0.1838 Accuracy is 97 %\n",
            "Completed training batch 395 Training Loss is: 0.1692 Validation Loss is: 0.1836 Accuracy is 97 %\n",
            "Completed training batch 396 Training Loss is: 0.1690 Validation Loss is: 0.1834 Accuracy is 97 %\n",
            "Completed training batch 397 Training Loss is: 0.1688 Validation Loss is: 0.1833 Accuracy is 97 %\n",
            "Completed training batch 398 Training Loss is: 0.1687 Validation Loss is: 0.1831 Accuracy is 97 %\n",
            "Completed training batch 399 Training Loss is: 0.1685 Validation Loss is: 0.1829 Accuracy is 97 %\n",
            "Completed training batch 400 Training Loss is: 0.1683 Validation Loss is: 0.1827 Accuracy is 97 %\n",
            "Completed training batch 401 Training Loss is: 0.1681 Validation Loss is: 0.1825 Accuracy is 97 %\n",
            "Completed training batch 402 Training Loss is: 0.1680 Validation Loss is: 0.1823 Accuracy is 97 %\n",
            "Completed training batch 403 Training Loss is: 0.1678 Validation Loss is: 0.1822 Accuracy is 97 %\n",
            "Completed training batch 404 Training Loss is: 0.1676 Validation Loss is: 0.1820 Accuracy is 97 %\n",
            "Completed training batch 405 Training Loss is: 0.1675 Validation Loss is: 0.1818 Accuracy is 97 %\n",
            "Completed training batch 406 Training Loss is: 0.1673 Validation Loss is: 0.1816 Accuracy is 97 %\n",
            "Completed training batch 407 Training Loss is: 0.1671 Validation Loss is: 0.1815 Accuracy is 97 %\n",
            "Completed training batch 408 Training Loss is: 0.1670 Validation Loss is: 0.1813 Accuracy is 97 %\n",
            "Completed training batch 409 Training Loss is: 0.1668 Validation Loss is: 0.1811 Accuracy is 97 %\n",
            "Completed training batch 410 Training Loss is: 0.1667 Validation Loss is: 0.1809 Accuracy is 97 %\n",
            "Completed training batch 411 Training Loss is: 0.1665 Validation Loss is: 0.1808 Accuracy is 97 %\n",
            "Completed training batch 412 Training Loss is: 0.1663 Validation Loss is: 0.1806 Accuracy is 97 %\n",
            "Completed training batch 413 Training Loss is: 0.1662 Validation Loss is: 0.1804 Accuracy is 97 %\n",
            "Completed training batch 414 Training Loss is: 0.1660 Validation Loss is: 0.1802 Accuracy is 97 %\n",
            "Completed training batch 415 Training Loss is: 0.1658 Validation Loss is: 0.1801 Accuracy is 97 %\n",
            "Completed training batch 416 Training Loss is: 0.1657 Validation Loss is: 0.1799 Accuracy is 97 %\n",
            "Completed training batch 417 Training Loss is: 0.1655 Validation Loss is: 0.1797 Accuracy is 97 %\n",
            "Completed training batch 418 Training Loss is: 0.1654 Validation Loss is: 0.1796 Accuracy is 97 %\n",
            "Completed training batch 419 Training Loss is: 0.1652 Validation Loss is: 0.1794 Accuracy is 97 %\n",
            "Completed training batch 420 Training Loss is: 0.1650 Validation Loss is: 0.1792 Accuracy is 97 %\n",
            "Completed training batch 421 Training Loss is: 0.1649 Validation Loss is: 0.1791 Accuracy is 97 %\n",
            "Completed training batch 422 Training Loss is: 0.1647 Validation Loss is: 0.1789 Accuracy is 97 %\n",
            "Completed training batch 423 Training Loss is: 0.1646 Validation Loss is: 0.1787 Accuracy is 97 %\n",
            "Completed training batch 424 Training Loss is: 0.1644 Validation Loss is: 0.1786 Accuracy is 97 %\n",
            "Completed training batch 425 Training Loss is: 0.1643 Validation Loss is: 0.1784 Accuracy is 97 %\n",
            "Completed training batch 426 Training Loss is: 0.1641 Validation Loss is: 0.1782 Accuracy is 97 %\n",
            "Completed training batch 427 Training Loss is: 0.1640 Validation Loss is: 0.1781 Accuracy is 97 %\n",
            "Completed training batch 428 Training Loss is: 0.1638 Validation Loss is: 0.1779 Accuracy is 97 %\n",
            "Completed training batch 429 Training Loss is: 0.1636 Validation Loss is: 0.1777 Accuracy is 97 %\n",
            "Completed training batch 430 Training Loss is: 0.1635 Validation Loss is: 0.1776 Accuracy is 97 %\n",
            "Completed training batch 431 Training Loss is: 0.1633 Validation Loss is: 0.1774 Accuracy is 97 %\n",
            "Completed training batch 432 Training Loss is: 0.1632 Validation Loss is: 0.1772 Accuracy is 97 %\n",
            "Completed training batch 433 Training Loss is: 0.1630 Validation Loss is: 0.1771 Accuracy is 97 %\n",
            "Completed training batch 434 Training Loss is: 0.1629 Validation Loss is: 0.1769 Accuracy is 97 %\n",
            "Completed training batch 435 Training Loss is: 0.1627 Validation Loss is: 0.1768 Accuracy is 97 %\n",
            "Completed training batch 436 Training Loss is: 0.1626 Validation Loss is: 0.1766 Accuracy is 97 %\n",
            "Completed training batch 437 Training Loss is: 0.1624 Validation Loss is: 0.1764 Accuracy is 97 %\n",
            "Completed training batch 438 Training Loss is: 0.1623 Validation Loss is: 0.1763 Accuracy is 97 %\n",
            "Completed training batch 439 Training Loss is: 0.1621 Validation Loss is: 0.1761 Accuracy is 97 %\n",
            "Completed training batch 440 Training Loss is: 0.1620 Validation Loss is: 0.1760 Accuracy is 97 %\n",
            "Completed training batch 441 Training Loss is: 0.1618 Validation Loss is: 0.1758 Accuracy is 97 %\n",
            "Completed training batch 442 Training Loss is: 0.1617 Validation Loss is: 0.1757 Accuracy is 97 %\n",
            "Completed training batch 443 Training Loss is: 0.1616 Validation Loss is: 0.1755 Accuracy is 97 %\n",
            "Completed training batch 444 Training Loss is: 0.1614 Validation Loss is: 0.1753 Accuracy is 97 %\n",
            "Completed training batch 445 Training Loss is: 0.1613 Validation Loss is: 0.1752 Accuracy is 97 %\n",
            "Completed training batch 446 Training Loss is: 0.1611 Validation Loss is: 0.1750 Accuracy is 97 %\n",
            "Completed training batch 447 Training Loss is: 0.1610 Validation Loss is: 0.1749 Accuracy is 97 %\n",
            "Completed training batch 448 Training Loss is: 0.1608 Validation Loss is: 0.1747 Accuracy is 97 %\n",
            "Completed training batch 449 Training Loss is: 0.1607 Validation Loss is: 0.1746 Accuracy is 97 %\n",
            "Completed training batch 450 Training Loss is: 0.1605 Validation Loss is: 0.1744 Accuracy is 97 %\n",
            "Completed training batch 451 Training Loss is: 0.1604 Validation Loss is: 0.1743 Accuracy is 97 %\n",
            "Completed training batch 452 Training Loss is: 0.1603 Validation Loss is: 0.1741 Accuracy is 97 %\n",
            "Completed training batch 453 Training Loss is: 0.1601 Validation Loss is: 0.1740 Accuracy is 97 %\n",
            "Completed training batch 454 Training Loss is: 0.1600 Validation Loss is: 0.1738 Accuracy is 97 %\n",
            "Completed training batch 455 Training Loss is: 0.1598 Validation Loss is: 0.1737 Accuracy is 97 %\n",
            "Completed training batch 456 Training Loss is: 0.1597 Validation Loss is: 0.1735 Accuracy is 97 %\n",
            "Completed training batch 457 Training Loss is: 0.1596 Validation Loss is: 0.1734 Accuracy is 97 %\n",
            "Completed training batch 458 Training Loss is: 0.1594 Validation Loss is: 0.1732 Accuracy is 97 %\n",
            "Completed training batch 459 Training Loss is: 0.1593 Validation Loss is: 0.1731 Accuracy is 97 %\n",
            "Completed training batch 460 Training Loss is: 0.1591 Validation Loss is: 0.1729 Accuracy is 97 %\n",
            "Completed training batch 461 Training Loss is: 0.1590 Validation Loss is: 0.1728 Accuracy is 97 %\n",
            "Completed training batch 462 Training Loss is: 0.1589 Validation Loss is: 0.1726 Accuracy is 97 %\n",
            "Completed training batch 463 Training Loss is: 0.1587 Validation Loss is: 0.1725 Accuracy is 97 %\n",
            "Completed training batch 464 Training Loss is: 0.1586 Validation Loss is: 0.1723 Accuracy is 97 %\n",
            "Completed training batch 465 Training Loss is: 0.1584 Validation Loss is: 0.1722 Accuracy is 97 %\n",
            "Completed training batch 466 Training Loss is: 0.1583 Validation Loss is: 0.1720 Accuracy is 97 %\n",
            "Completed training batch 467 Training Loss is: 0.1582 Validation Loss is: 0.1719 Accuracy is 97 %\n",
            "Completed training batch 468 Training Loss is: 0.1580 Validation Loss is: 0.1718 Accuracy is 97 %\n",
            "Completed training batch 469 Training Loss is: 0.1579 Validation Loss is: 0.1716 Accuracy is 97 %\n",
            "Completed training batch 470 Training Loss is: 0.1578 Validation Loss is: 0.1715 Accuracy is 97 %\n",
            "Completed training batch 471 Training Loss is: 0.1576 Validation Loss is: 0.1713 Accuracy is 97 %\n",
            "Completed training batch 472 Training Loss is: 0.1575 Validation Loss is: 0.1712 Accuracy is 97 %\n",
            "Completed training batch 473 Training Loss is: 0.1574 Validation Loss is: 0.1710 Accuracy is 97 %\n",
            "Completed training batch 474 Training Loss is: 0.1572 Validation Loss is: 0.1709 Accuracy is 97 %\n",
            "Completed training batch 475 Training Loss is: 0.1571 Validation Loss is: 0.1708 Accuracy is 97 %\n",
            "Completed training batch 476 Training Loss is: 0.1570 Validation Loss is: 0.1706 Accuracy is 97 %\n",
            "Completed training batch 477 Training Loss is: 0.1568 Validation Loss is: 0.1705 Accuracy is 97 %\n",
            "Completed training batch 478 Training Loss is: 0.1567 Validation Loss is: 0.1703 Accuracy is 97 %\n",
            "Completed training batch 479 Training Loss is: 0.1566 Validation Loss is: 0.1702 Accuracy is 97 %\n",
            "Completed training batch 480 Training Loss is: 0.1565 Validation Loss is: 0.1701 Accuracy is 97 %\n",
            "Completed training batch 481 Training Loss is: 0.1563 Validation Loss is: 0.1699 Accuracy is 97 %\n",
            "Completed training batch 482 Training Loss is: 0.1562 Validation Loss is: 0.1698 Accuracy is 97 %\n",
            "Completed training batch 483 Training Loss is: 0.1561 Validation Loss is: 0.1697 Accuracy is 97 %\n",
            "Completed training batch 484 Training Loss is: 0.1559 Validation Loss is: 0.1695 Accuracy is 97 %\n",
            "Completed training batch 485 Training Loss is: 0.1558 Validation Loss is: 0.1694 Accuracy is 97 %\n",
            "Completed training batch 486 Training Loss is: 0.1557 Validation Loss is: 0.1692 Accuracy is 97 %\n",
            "Completed training batch 487 Training Loss is: 0.1555 Validation Loss is: 0.1691 Accuracy is 97 %\n",
            "Completed training batch 488 Training Loss is: 0.1554 Validation Loss is: 0.1690 Accuracy is 97 %\n",
            "Completed training batch 489 Training Loss is: 0.1553 Validation Loss is: 0.1688 Accuracy is 97 %\n",
            "Completed training batch 490 Training Loss is: 0.1552 Validation Loss is: 0.1687 Accuracy is 97 %\n",
            "Completed training batch 491 Training Loss is: 0.1550 Validation Loss is: 0.1686 Accuracy is 97 %\n",
            "Completed training batch 492 Training Loss is: 0.1549 Validation Loss is: 0.1684 Accuracy is 97 %\n",
            "Completed training batch 493 Training Loss is: 0.1548 Validation Loss is: 0.1683 Accuracy is 97 %\n",
            "Completed training batch 494 Training Loss is: 0.1547 Validation Loss is: 0.1682 Accuracy is 97 %\n",
            "Completed training batch 495 Training Loss is: 0.1545 Validation Loss is: 0.1680 Accuracy is 97 %\n",
            "Completed training batch 496 Training Loss is: 0.1544 Validation Loss is: 0.1679 Accuracy is 97 %\n",
            "Completed training batch 497 Training Loss is: 0.1543 Validation Loss is: 0.1678 Accuracy is 97 %\n",
            "Completed training batch 498 Training Loss is: 0.1542 Validation Loss is: 0.1676 Accuracy is 97 %\n",
            "Completed training batch 499 Training Loss is: 0.1540 Validation Loss is: 0.1675 Accuracy is 97 %\n",
            "Completed training batch 500 Training Loss is: 0.1539 Validation Loss is: 0.1674 Accuracy is 97 %\n",
            "Completed training batch 501 Training Loss is: 0.1538 Validation Loss is: 0.1673 Accuracy is 97 %\n",
            "Completed training batch 502 Training Loss is: 0.1537 Validation Loss is: 0.1671 Accuracy is 97 %\n",
            "Completed training batch 503 Training Loss is: 0.1536 Validation Loss is: 0.1670 Accuracy is 97 %\n",
            "Completed training batch 504 Training Loss is: 0.1534 Validation Loss is: 0.1669 Accuracy is 97 %\n",
            "Completed training batch 505 Training Loss is: 0.1533 Validation Loss is: 0.1667 Accuracy is 97 %\n",
            "Completed training batch 506 Training Loss is: 0.1532 Validation Loss is: 0.1666 Accuracy is 97 %\n",
            "Completed training batch 507 Training Loss is: 0.1531 Validation Loss is: 0.1665 Accuracy is 97 %\n",
            "Completed training batch 508 Training Loss is: 0.1530 Validation Loss is: 0.1664 Accuracy is 97 %\n",
            "Completed training batch 509 Training Loss is: 0.1528 Validation Loss is: 0.1662 Accuracy is 97 %\n",
            "Completed training batch 510 Training Loss is: 0.1527 Validation Loss is: 0.1661 Accuracy is 97 %\n",
            "Completed training batch 511 Training Loss is: 0.1526 Validation Loss is: 0.1660 Accuracy is 97 %\n",
            "Completed training batch 512 Training Loss is: 0.1525 Validation Loss is: 0.1658 Accuracy is 97 %\n",
            "Completed training batch 513 Training Loss is: 0.1524 Validation Loss is: 0.1657 Accuracy is 97 %\n",
            "Completed training batch 514 Training Loss is: 0.1522 Validation Loss is: 0.1656 Accuracy is 97 %\n",
            "Completed training batch 515 Training Loss is: 0.1521 Validation Loss is: 0.1655 Accuracy is 97 %\n",
            "Completed training batch 516 Training Loss is: 0.1520 Validation Loss is: 0.1653 Accuracy is 97 %\n",
            "Completed training batch 517 Training Loss is: 0.1519 Validation Loss is: 0.1652 Accuracy is 97 %\n",
            "Completed training batch 518 Training Loss is: 0.1518 Validation Loss is: 0.1651 Accuracy is 97 %\n",
            "Completed training batch 519 Training Loss is: 0.1517 Validation Loss is: 0.1650 Accuracy is 97 %\n",
            "Completed training batch 520 Training Loss is: 0.1515 Validation Loss is: 0.1648 Accuracy is 97 %\n",
            "Completed training batch 521 Training Loss is: 0.1514 Validation Loss is: 0.1647 Accuracy is 97 %\n",
            "Completed training batch 522 Training Loss is: 0.1513 Validation Loss is: 0.1646 Accuracy is 97 %\n",
            "Completed training batch 523 Training Loss is: 0.1512 Validation Loss is: 0.1645 Accuracy is 97 %\n",
            "Completed training batch 524 Training Loss is: 0.1511 Validation Loss is: 0.1644 Accuracy is 97 %\n",
            "Completed training batch 525 Training Loss is: 0.1510 Validation Loss is: 0.1642 Accuracy is 97 %\n",
            "Completed training batch 526 Training Loss is: 0.1509 Validation Loss is: 0.1641 Accuracy is 97 %\n",
            "Completed training batch 527 Training Loss is: 0.1507 Validation Loss is: 0.1640 Accuracy is 97 %\n",
            "Completed training batch 528 Training Loss is: 0.1506 Validation Loss is: 0.1639 Accuracy is 97 %\n",
            "Completed training batch 529 Training Loss is: 0.1505 Validation Loss is: 0.1638 Accuracy is 97 %\n",
            "Completed training batch 530 Training Loss is: 0.1504 Validation Loss is: 0.1636 Accuracy is 97 %\n",
            "Completed training batch 531 Training Loss is: 0.1503 Validation Loss is: 0.1635 Accuracy is 97 %\n",
            "Completed training batch 532 Training Loss is: 0.1502 Validation Loss is: 0.1634 Accuracy is 97 %\n",
            "Completed training batch 533 Training Loss is: 0.1501 Validation Loss is: 0.1633 Accuracy is 97 %\n",
            "Completed training batch 534 Training Loss is: 0.1500 Validation Loss is: 0.1632 Accuracy is 97 %\n",
            "Completed training batch 535 Training Loss is: 0.1498 Validation Loss is: 0.1630 Accuracy is 97 %\n",
            "Completed training batch 536 Training Loss is: 0.1497 Validation Loss is: 0.1629 Accuracy is 97 %\n",
            "Completed training batch 537 Training Loss is: 0.1496 Validation Loss is: 0.1628 Accuracy is 97 %\n",
            "Completed training batch 538 Training Loss is: 0.1495 Validation Loss is: 0.1627 Accuracy is 97 %\n",
            "Completed training batch 539 Training Loss is: 0.1494 Validation Loss is: 0.1626 Accuracy is 97 %\n",
            "Completed training batch 540 Training Loss is: 0.1493 Validation Loss is: 0.1625 Accuracy is 97 %\n",
            "Completed training batch 541 Training Loss is: 0.1492 Validation Loss is: 0.1623 Accuracy is 97 %\n",
            "Completed training batch 542 Training Loss is: 0.1491 Validation Loss is: 0.1622 Accuracy is 97 %\n",
            "Completed training batch 543 Training Loss is: 0.1490 Validation Loss is: 0.1621 Accuracy is 97 %\n",
            "Completed training batch 544 Training Loss is: 0.1489 Validation Loss is: 0.1620 Accuracy is 97 %\n",
            "Completed training batch 545 Training Loss is: 0.1487 Validation Loss is: 0.1619 Accuracy is 97 %\n",
            "Completed training batch 546 Training Loss is: 0.1486 Validation Loss is: 0.1618 Accuracy is 97 %\n",
            "Completed training batch 547 Training Loss is: 0.1485 Validation Loss is: 0.1616 Accuracy is 97 %\n",
            "Completed training batch 548 Training Loss is: 0.1484 Validation Loss is: 0.1615 Accuracy is 97 %\n",
            "Completed training batch 549 Training Loss is: 0.1483 Validation Loss is: 0.1614 Accuracy is 97 %\n",
            "Completed training batch 550 Training Loss is: 0.1482 Validation Loss is: 0.1613 Accuracy is 97 %\n",
            "Completed training batch 551 Training Loss is: 0.1481 Validation Loss is: 0.1612 Accuracy is 97 %\n",
            "Completed training batch 552 Training Loss is: 0.1480 Validation Loss is: 0.1611 Accuracy is 97 %\n",
            "Completed training batch 553 Training Loss is: 0.1479 Validation Loss is: 0.1610 Accuracy is 97 %\n",
            "Completed training batch 554 Training Loss is: 0.1478 Validation Loss is: 0.1609 Accuracy is 97 %\n",
            "Completed training batch 555 Training Loss is: 0.1477 Validation Loss is: 0.1607 Accuracy is 97 %\n",
            "Completed training batch 556 Training Loss is: 0.1476 Validation Loss is: 0.1606 Accuracy is 97 %\n",
            "Completed training batch 557 Training Loss is: 0.1475 Validation Loss is: 0.1605 Accuracy is 97 %\n",
            "Completed training batch 558 Training Loss is: 0.1474 Validation Loss is: 0.1604 Accuracy is 97 %\n",
            "Completed training batch 559 Training Loss is: 0.1473 Validation Loss is: 0.1603 Accuracy is 97 %\n",
            "Completed training batch 560 Training Loss is: 0.1472 Validation Loss is: 0.1602 Accuracy is 97 %\n",
            "Completed training batch 561 Training Loss is: 0.1471 Validation Loss is: 0.1601 Accuracy is 97 %\n",
            "Completed training batch 562 Training Loss is: 0.1470 Validation Loss is: 0.1600 Accuracy is 97 %\n",
            "Completed training batch 563 Training Loss is: 0.1469 Validation Loss is: 0.1599 Accuracy is 97 %\n",
            "Completed training batch 564 Training Loss is: 0.1467 Validation Loss is: 0.1598 Accuracy is 97 %\n",
            "Completed training batch 565 Training Loss is: 0.1466 Validation Loss is: 0.1597 Accuracy is 97 %\n",
            "Completed training batch 566 Training Loss is: 0.1465 Validation Loss is: 0.1595 Accuracy is 97 %\n",
            "Completed training batch 567 Training Loss is: 0.1464 Validation Loss is: 0.1594 Accuracy is 97 %\n",
            "Completed training batch 568 Training Loss is: 0.1463 Validation Loss is: 0.1593 Accuracy is 97 %\n",
            "Completed training batch 569 Training Loss is: 0.1462 Validation Loss is: 0.1592 Accuracy is 97 %\n",
            "Completed training batch 570 Training Loss is: 0.1461 Validation Loss is: 0.1591 Accuracy is 97 %\n",
            "Completed training batch 571 Training Loss is: 0.1460 Validation Loss is: 0.1590 Accuracy is 97 %\n",
            "Completed training batch 572 Training Loss is: 0.1459 Validation Loss is: 0.1589 Accuracy is 97 %\n",
            "Completed training batch 573 Training Loss is: 0.1458 Validation Loss is: 0.1588 Accuracy is 97 %\n",
            "Completed training batch 574 Training Loss is: 0.1457 Validation Loss is: 0.1587 Accuracy is 97 %\n",
            "Completed training batch 575 Training Loss is: 0.1456 Validation Loss is: 0.1586 Accuracy is 97 %\n",
            "Completed training batch 576 Training Loss is: 0.1455 Validation Loss is: 0.1585 Accuracy is 97 %\n",
            "Completed training batch 577 Training Loss is: 0.1454 Validation Loss is: 0.1584 Accuracy is 97 %\n",
            "Completed training batch 578 Training Loss is: 0.1453 Validation Loss is: 0.1583 Accuracy is 97 %\n",
            "Completed training batch 579 Training Loss is: 0.1452 Validation Loss is: 0.1582 Accuracy is 97 %\n",
            "Completed training batch 580 Training Loss is: 0.1451 Validation Loss is: 0.1581 Accuracy is 97 %\n",
            "Completed training batch 581 Training Loss is: 0.1450 Validation Loss is: 0.1580 Accuracy is 97 %\n",
            "Completed training batch 582 Training Loss is: 0.1449 Validation Loss is: 0.1579 Accuracy is 97 %\n",
            "Completed training batch 583 Training Loss is: 0.1448 Validation Loss is: 0.1577 Accuracy is 97 %\n",
            "Completed training batch 584 Training Loss is: 0.1447 Validation Loss is: 0.1576 Accuracy is 97 %\n",
            "Completed training batch 585 Training Loss is: 0.1447 Validation Loss is: 0.1575 Accuracy is 97 %\n",
            "Completed training batch 586 Training Loss is: 0.1446 Validation Loss is: 0.1574 Accuracy is 97 %\n",
            "Completed training batch 587 Training Loss is: 0.1445 Validation Loss is: 0.1573 Accuracy is 97 %\n",
            "Completed training batch 588 Training Loss is: 0.1444 Validation Loss is: 0.1572 Accuracy is 97 %\n",
            "Completed training batch 589 Training Loss is: 0.1443 Validation Loss is: 0.1571 Accuracy is 97 %\n",
            "Completed training batch 590 Training Loss is: 0.1442 Validation Loss is: 0.1570 Accuracy is 97 %\n",
            "Completed training batch 591 Training Loss is: 0.1441 Validation Loss is: 0.1569 Accuracy is 97 %\n",
            "Completed training batch 592 Training Loss is: 0.1440 Validation Loss is: 0.1568 Accuracy is 97 %\n",
            "Completed training batch 593 Training Loss is: 0.1439 Validation Loss is: 0.1567 Accuracy is 97 %\n",
            "Completed training batch 594 Training Loss is: 0.1438 Validation Loss is: 0.1566 Accuracy is 97 %\n",
            "Completed training batch 595 Training Loss is: 0.1437 Validation Loss is: 0.1565 Accuracy is 97 %\n",
            "Completed training batch 596 Training Loss is: 0.1436 Validation Loss is: 0.1564 Accuracy is 97 %\n",
            "Completed training batch 597 Training Loss is: 0.1435 Validation Loss is: 0.1563 Accuracy is 97 %\n",
            "Completed training batch 598 Training Loss is: 0.1434 Validation Loss is: 0.1562 Accuracy is 97 %\n",
            "Completed training batch 599 Training Loss is: 0.1433 Validation Loss is: 0.1561 Accuracy is 97 %\n",
            "Completed training batch 600 Training Loss is: 0.1432 Validation Loss is: 0.1560 Accuracy is 97 %\n",
            "Completed training batch 601 Training Loss is: 0.1431 Validation Loss is: 0.1559 Accuracy is 97 %\n",
            "Completed training batch 602 Training Loss is: 0.1430 Validation Loss is: 0.1558 Accuracy is 97 %\n",
            "Completed training batch 603 Training Loss is: 0.1429 Validation Loss is: 0.1557 Accuracy is 97 %\n",
            "Completed training batch 604 Training Loss is: 0.1428 Validation Loss is: 0.1556 Accuracy is 97 %\n",
            "Completed training batch 605 Training Loss is: 0.1428 Validation Loss is: 0.1555 Accuracy is 97 %\n",
            "Completed training batch 606 Training Loss is: 0.1427 Validation Loss is: 0.1554 Accuracy is 97 %\n",
            "Completed training batch 607 Training Loss is: 0.1426 Validation Loss is: 0.1553 Accuracy is 97 %\n",
            "Completed training batch 608 Training Loss is: 0.1425 Validation Loss is: 0.1552 Accuracy is 97 %\n",
            "Completed training batch 609 Training Loss is: 0.1424 Validation Loss is: 0.1551 Accuracy is 97 %\n",
            "Completed training batch 610 Training Loss is: 0.1423 Validation Loss is: 0.1550 Accuracy is 97 %\n",
            "Completed training batch 611 Training Loss is: 0.1422 Validation Loss is: 0.1550 Accuracy is 97 %\n",
            "Completed training batch 612 Training Loss is: 0.1421 Validation Loss is: 0.1549 Accuracy is 97 %\n",
            "Completed training batch 613 Training Loss is: 0.1420 Validation Loss is: 0.1548 Accuracy is 97 %\n",
            "Completed training batch 614 Training Loss is: 0.1419 Validation Loss is: 0.1547 Accuracy is 97 %\n",
            "Completed training batch 615 Training Loss is: 0.1418 Validation Loss is: 0.1546 Accuracy is 97 %\n",
            "Completed training batch 616 Training Loss is: 0.1418 Validation Loss is: 0.1545 Accuracy is 97 %\n",
            "Completed training batch 617 Training Loss is: 0.1417 Validation Loss is: 0.1544 Accuracy is 97 %\n",
            "Completed training batch 618 Training Loss is: 0.1416 Validation Loss is: 0.1543 Accuracy is 97 %\n",
            "Completed training batch 619 Training Loss is: 0.1415 Validation Loss is: 0.1542 Accuracy is 97 %\n",
            "Completed training batch 620 Training Loss is: 0.1414 Validation Loss is: 0.1541 Accuracy is 97 %\n",
            "Completed training batch 621 Training Loss is: 0.1413 Validation Loss is: 0.1540 Accuracy is 97 %\n",
            "Completed training batch 622 Training Loss is: 0.1412 Validation Loss is: 0.1539 Accuracy is 97 %\n",
            "Completed training batch 623 Training Loss is: 0.1411 Validation Loss is: 0.1538 Accuracy is 97 %\n",
            "Completed training batch 624 Training Loss is: 0.1410 Validation Loss is: 0.1537 Accuracy is 97 %\n",
            "Completed training batch 625 Training Loss is: 0.1409 Validation Loss is: 0.1536 Accuracy is 97 %\n",
            "Completed training batch 626 Training Loss is: 0.1409 Validation Loss is: 0.1535 Accuracy is 97 %\n",
            "Completed training batch 627 Training Loss is: 0.1408 Validation Loss is: 0.1534 Accuracy is 97 %\n",
            "Completed training batch 628 Training Loss is: 0.1407 Validation Loss is: 0.1533 Accuracy is 97 %\n",
            "Completed training batch 629 Training Loss is: 0.1406 Validation Loss is: 0.1532 Accuracy is 97 %\n",
            "Completed training batch 630 Training Loss is: 0.1405 Validation Loss is: 0.1532 Accuracy is 97 %\n",
            "Completed training batch 631 Training Loss is: 0.1404 Validation Loss is: 0.1531 Accuracy is 97 %\n",
            "Completed training batch 632 Training Loss is: 0.1403 Validation Loss is: 0.1530 Accuracy is 97 %\n",
            "Completed training batch 633 Training Loss is: 0.1403 Validation Loss is: 0.1529 Accuracy is 97 %\n",
            "Completed training batch 634 Training Loss is: 0.1402 Validation Loss is: 0.1528 Accuracy is 97 %\n",
            "Completed training batch 635 Training Loss is: 0.1401 Validation Loss is: 0.1527 Accuracy is 97 %\n",
            "Completed training batch 636 Training Loss is: 0.1400 Validation Loss is: 0.1526 Accuracy is 97 %\n",
            "Completed training batch 637 Training Loss is: 0.1399 Validation Loss is: 0.1525 Accuracy is 97 %\n",
            "Completed training batch 638 Training Loss is: 0.1398 Validation Loss is: 0.1524 Accuracy is 97 %\n",
            "Completed training batch 639 Training Loss is: 0.1397 Validation Loss is: 0.1523 Accuracy is 97 %\n",
            "Completed training batch 640 Training Loss is: 0.1397 Validation Loss is: 0.1522 Accuracy is 97 %\n",
            "Completed training batch 641 Training Loss is: 0.1396 Validation Loss is: 0.1522 Accuracy is 97 %\n",
            "Completed training batch 642 Training Loss is: 0.1395 Validation Loss is: 0.1521 Accuracy is 97 %\n",
            "Completed training batch 643 Training Loss is: 0.1394 Validation Loss is: 0.1520 Accuracy is 97 %\n",
            "Completed training batch 644 Training Loss is: 0.1393 Validation Loss is: 0.1519 Accuracy is 97 %\n",
            "Completed training batch 645 Training Loss is: 0.1392 Validation Loss is: 0.1518 Accuracy is 97 %\n",
            "Completed training batch 646 Training Loss is: 0.1391 Validation Loss is: 0.1517 Accuracy is 97 %\n",
            "Completed training batch 647 Training Loss is: 0.1391 Validation Loss is: 0.1516 Accuracy is 97 %\n",
            "Completed training batch 648 Training Loss is: 0.1390 Validation Loss is: 0.1515 Accuracy is 97 %\n",
            "Completed training batch 649 Training Loss is: 0.1389 Validation Loss is: 0.1514 Accuracy is 97 %\n",
            "Completed training batch 650 Training Loss is: 0.1388 Validation Loss is: 0.1514 Accuracy is 97 %\n",
            "Completed training batch 651 Training Loss is: 0.1387 Validation Loss is: 0.1513 Accuracy is 97 %\n",
            "Completed training batch 652 Training Loss is: 0.1386 Validation Loss is: 0.1512 Accuracy is 97 %\n",
            "Completed training batch 653 Training Loss is: 0.1386 Validation Loss is: 0.1511 Accuracy is 97 %\n",
            "Completed training batch 654 Training Loss is: 0.1385 Validation Loss is: 0.1510 Accuracy is 97 %\n",
            "Completed training batch 655 Training Loss is: 0.1384 Validation Loss is: 0.1509 Accuracy is 97 %\n",
            "Completed training batch 656 Training Loss is: 0.1383 Validation Loss is: 0.1508 Accuracy is 97 %\n",
            "Completed training batch 657 Training Loss is: 0.1382 Validation Loss is: 0.1507 Accuracy is 97 %\n",
            "Completed training batch 658 Training Loss is: 0.1382 Validation Loss is: 0.1507 Accuracy is 97 %\n",
            "Completed training batch 659 Training Loss is: 0.1381 Validation Loss is: 0.1506 Accuracy is 97 %\n",
            "Completed training batch 660 Training Loss is: 0.1380 Validation Loss is: 0.1505 Accuracy is 97 %\n",
            "Completed training batch 661 Training Loss is: 0.1379 Validation Loss is: 0.1504 Accuracy is 97 %\n",
            "Completed training batch 662 Training Loss is: 0.1378 Validation Loss is: 0.1503 Accuracy is 97 %\n",
            "Completed training batch 663 Training Loss is: 0.1377 Validation Loss is: 0.1502 Accuracy is 97 %\n",
            "Completed training batch 664 Training Loss is: 0.1377 Validation Loss is: 0.1501 Accuracy is 97 %\n",
            "Completed training batch 665 Training Loss is: 0.1376 Validation Loss is: 0.1501 Accuracy is 97 %\n",
            "Completed training batch 666 Training Loss is: 0.1375 Validation Loss is: 0.1500 Accuracy is 97 %\n",
            "Completed training batch 667 Training Loss is: 0.1374 Validation Loss is: 0.1499 Accuracy is 97 %\n",
            "Completed training batch 668 Training Loss is: 0.1373 Validation Loss is: 0.1498 Accuracy is 97 %\n",
            "Completed training batch 669 Training Loss is: 0.1373 Validation Loss is: 0.1497 Accuracy is 97 %\n",
            "Completed training batch 670 Training Loss is: 0.1372 Validation Loss is: 0.1496 Accuracy is 97 %\n",
            "Completed training batch 671 Training Loss is: 0.1371 Validation Loss is: 0.1495 Accuracy is 97 %\n",
            "Completed training batch 672 Training Loss is: 0.1370 Validation Loss is: 0.1495 Accuracy is 97 %\n",
            "Completed training batch 673 Training Loss is: 0.1369 Validation Loss is: 0.1494 Accuracy is 97 %\n",
            "Completed training batch 674 Training Loss is: 0.1369 Validation Loss is: 0.1493 Accuracy is 97 %\n",
            "Completed training batch 675 Training Loss is: 0.1368 Validation Loss is: 0.1492 Accuracy is 97 %\n",
            "Completed training batch 676 Training Loss is: 0.1367 Validation Loss is: 0.1491 Accuracy is 97 %\n",
            "Completed training batch 677 Training Loss is: 0.1366 Validation Loss is: 0.1490 Accuracy is 97 %\n",
            "Completed training batch 678 Training Loss is: 0.1366 Validation Loss is: 0.1490 Accuracy is 97 %\n",
            "Completed training batch 679 Training Loss is: 0.1365 Validation Loss is: 0.1489 Accuracy is 97 %\n",
            "Completed training batch 680 Training Loss is: 0.1364 Validation Loss is: 0.1488 Accuracy is 97 %\n",
            "Completed training batch 681 Training Loss is: 0.1363 Validation Loss is: 0.1487 Accuracy is 97 %\n",
            "Completed training batch 682 Training Loss is: 0.1362 Validation Loss is: 0.1486 Accuracy is 97 %\n",
            "Completed training batch 683 Training Loss is: 0.1362 Validation Loss is: 0.1486 Accuracy is 97 %\n",
            "Completed training batch 684 Training Loss is: 0.1361 Validation Loss is: 0.1485 Accuracy is 97 %\n",
            "Completed training batch 685 Training Loss is: 0.1360 Validation Loss is: 0.1484 Accuracy is 97 %\n",
            "Completed training batch 686 Training Loss is: 0.1359 Validation Loss is: 0.1483 Accuracy is 97 %\n",
            "Completed training batch 687 Training Loss is: 0.1359 Validation Loss is: 0.1482 Accuracy is 97 %\n",
            "Completed training batch 688 Training Loss is: 0.1358 Validation Loss is: 0.1481 Accuracy is 97 %\n",
            "Completed training batch 689 Training Loss is: 0.1357 Validation Loss is: 0.1481 Accuracy is 97 %\n",
            "Completed training batch 690 Training Loss is: 0.1356 Validation Loss is: 0.1480 Accuracy is 97 %\n",
            "Completed training batch 691 Training Loss is: 0.1356 Validation Loss is: 0.1479 Accuracy is 97 %\n",
            "Completed training batch 692 Training Loss is: 0.1355 Validation Loss is: 0.1478 Accuracy is 97 %\n",
            "Completed training batch 693 Training Loss is: 0.1354 Validation Loss is: 0.1477 Accuracy is 97 %\n",
            "Completed training batch 694 Training Loss is: 0.1353 Validation Loss is: 0.1477 Accuracy is 97 %\n",
            "Completed training batch 695 Training Loss is: 0.1353 Validation Loss is: 0.1476 Accuracy is 97 %\n",
            "Completed training batch 696 Training Loss is: 0.1352 Validation Loss is: 0.1475 Accuracy is 97 %\n",
            "Completed training batch 697 Training Loss is: 0.1351 Validation Loss is: 0.1474 Accuracy is 97 %\n",
            "Completed training batch 698 Training Loss is: 0.1350 Validation Loss is: 0.1473 Accuracy is 97 %\n",
            "Completed training batch 699 Training Loss is: 0.1350 Validation Loss is: 0.1473 Accuracy is 97 %\n",
            "Completed training batch 700 Training Loss is: 0.1349 Validation Loss is: 0.1472 Accuracy is 97 %\n",
            "Completed training batch 701 Training Loss is: 0.1348 Validation Loss is: 0.1471 Accuracy is 97 %\n",
            "Completed training batch 702 Training Loss is: 0.1347 Validation Loss is: 0.1470 Accuracy is 97 %\n",
            "Completed training batch 703 Training Loss is: 0.1347 Validation Loss is: 0.1470 Accuracy is 97 %\n",
            "Completed training batch 704 Training Loss is: 0.1346 Validation Loss is: 0.1469 Accuracy is 97 %\n",
            "Completed training batch 705 Training Loss is: 0.1345 Validation Loss is: 0.1468 Accuracy is 97 %\n",
            "Completed training batch 706 Training Loss is: 0.1344 Validation Loss is: 0.1467 Accuracy is 97 %\n",
            "Completed training batch 707 Training Loss is: 0.1344 Validation Loss is: 0.1466 Accuracy is 97 %\n",
            "Completed training batch 708 Training Loss is: 0.1343 Validation Loss is: 0.1466 Accuracy is 97 %\n",
            "Completed training batch 709 Training Loss is: 0.1342 Validation Loss is: 0.1465 Accuracy is 97 %\n",
            "Completed training batch 710 Training Loss is: 0.1341 Validation Loss is: 0.1464 Accuracy is 97 %\n",
            "Completed training batch 711 Training Loss is: 0.1341 Validation Loss is: 0.1463 Accuracy is 97 %\n",
            "Completed training batch 712 Training Loss is: 0.1340 Validation Loss is: 0.1463 Accuracy is 97 %\n",
            "Completed training batch 713 Training Loss is: 0.1339 Validation Loss is: 0.1462 Accuracy is 97 %\n",
            "Completed training batch 714 Training Loss is: 0.1339 Validation Loss is: 0.1461 Accuracy is 97 %\n",
            "Completed training batch 715 Training Loss is: 0.1338 Validation Loss is: 0.1460 Accuracy is 97 %\n",
            "Completed training batch 716 Training Loss is: 0.1337 Validation Loss is: 0.1460 Accuracy is 97 %\n",
            "Completed training batch 717 Training Loss is: 0.1336 Validation Loss is: 0.1459 Accuracy is 97 %\n",
            "Completed training batch 718 Training Loss is: 0.1336 Validation Loss is: 0.1458 Accuracy is 97 %\n",
            "Completed training batch 719 Training Loss is: 0.1335 Validation Loss is: 0.1457 Accuracy is 97 %\n",
            "Completed training batch 720 Training Loss is: 0.1334 Validation Loss is: 0.1456 Accuracy is 97 %\n",
            "Completed training batch 721 Training Loss is: 0.1334 Validation Loss is: 0.1456 Accuracy is 97 %\n",
            "Completed training batch 722 Training Loss is: 0.1333 Validation Loss is: 0.1455 Accuracy is 97 %\n",
            "Completed training batch 723 Training Loss is: 0.1332 Validation Loss is: 0.1454 Accuracy is 97 %\n",
            "Completed training batch 724 Training Loss is: 0.1331 Validation Loss is: 0.1453 Accuracy is 97 %\n",
            "Completed training batch 725 Training Loss is: 0.1331 Validation Loss is: 0.1453 Accuracy is 97 %\n",
            "Completed training batch 726 Training Loss is: 0.1330 Validation Loss is: 0.1452 Accuracy is 97 %\n",
            "Completed training batch 727 Training Loss is: 0.1329 Validation Loss is: 0.1451 Accuracy is 97 %\n",
            "Completed training batch 728 Training Loss is: 0.1329 Validation Loss is: 0.1450 Accuracy is 97 %\n",
            "Completed training batch 729 Training Loss is: 0.1328 Validation Loss is: 0.1450 Accuracy is 97 %\n",
            "Completed training batch 730 Training Loss is: 0.1327 Validation Loss is: 0.1449 Accuracy is 97 %\n",
            "Completed training batch 731 Training Loss is: 0.1327 Validation Loss is: 0.1448 Accuracy is 97 %\n",
            "Completed training batch 732 Training Loss is: 0.1326 Validation Loss is: 0.1448 Accuracy is 97 %\n",
            "Completed training batch 733 Training Loss is: 0.1325 Validation Loss is: 0.1447 Accuracy is 97 %\n",
            "Completed training batch 734 Training Loss is: 0.1324 Validation Loss is: 0.1446 Accuracy is 97 %\n",
            "Completed training batch 735 Training Loss is: 0.1324 Validation Loss is: 0.1445 Accuracy is 97 %\n",
            "Completed training batch 736 Training Loss is: 0.1323 Validation Loss is: 0.1445 Accuracy is 97 %\n",
            "Completed training batch 737 Training Loss is: 0.1322 Validation Loss is: 0.1444 Accuracy is 97 %\n",
            "Completed training batch 738 Training Loss is: 0.1322 Validation Loss is: 0.1443 Accuracy is 97 %\n",
            "Completed training batch 739 Training Loss is: 0.1321 Validation Loss is: 0.1442 Accuracy is 97 %\n",
            "Completed training batch 740 Training Loss is: 0.1320 Validation Loss is: 0.1442 Accuracy is 97 %\n",
            "Completed training batch 741 Training Loss is: 0.1320 Validation Loss is: 0.1441 Accuracy is 97 %\n",
            "Completed training batch 742 Training Loss is: 0.1319 Validation Loss is: 0.1440 Accuracy is 97 %\n",
            "Completed training batch 743 Training Loss is: 0.1318 Validation Loss is: 0.1440 Accuracy is 97 %\n",
            "Completed training batch 744 Training Loss is: 0.1318 Validation Loss is: 0.1439 Accuracy is 97 %\n",
            "Completed training batch 745 Training Loss is: 0.1317 Validation Loss is: 0.1438 Accuracy is 97 %\n",
            "Completed training batch 746 Training Loss is: 0.1316 Validation Loss is: 0.1437 Accuracy is 97 %\n",
            "Completed training batch 747 Training Loss is: 0.1316 Validation Loss is: 0.1437 Accuracy is 97 %\n",
            "Completed training batch 748 Training Loss is: 0.1315 Validation Loss is: 0.1436 Accuracy is 97 %\n",
            "Completed training batch 749 Training Loss is: 0.1314 Validation Loss is: 0.1435 Accuracy is 97 %\n",
            "Completed training batch 750 Training Loss is: 0.1314 Validation Loss is: 0.1435 Accuracy is 97 %\n",
            "Completed training batch 751 Training Loss is: 0.1313 Validation Loss is: 0.1434 Accuracy is 97 %\n",
            "Completed training batch 752 Training Loss is: 0.1312 Validation Loss is: 0.1433 Accuracy is 97 %\n",
            "Completed training batch 753 Training Loss is: 0.1312 Validation Loss is: 0.1432 Accuracy is 97 %\n",
            "Completed training batch 754 Training Loss is: 0.1311 Validation Loss is: 0.1432 Accuracy is 97 %\n",
            "Completed training batch 755 Training Loss is: 0.1310 Validation Loss is: 0.1431 Accuracy is 97 %\n",
            "Completed training batch 756 Training Loss is: 0.1310 Validation Loss is: 0.1430 Accuracy is 97 %\n",
            "Completed training batch 757 Training Loss is: 0.1309 Validation Loss is: 0.1430 Accuracy is 97 %\n",
            "Completed training batch 758 Training Loss is: 0.1308 Validation Loss is: 0.1429 Accuracy is 97 %\n",
            "Completed training batch 759 Training Loss is: 0.1308 Validation Loss is: 0.1428 Accuracy is 97 %\n",
            "Completed training batch 760 Training Loss is: 0.1307 Validation Loss is: 0.1427 Accuracy is 97 %\n",
            "Completed training batch 761 Training Loss is: 0.1306 Validation Loss is: 0.1427 Accuracy is 97 %\n",
            "Completed training batch 762 Training Loss is: 0.1306 Validation Loss is: 0.1426 Accuracy is 97 %\n",
            "Completed training batch 763 Training Loss is: 0.1305 Validation Loss is: 0.1425 Accuracy is 97 %\n",
            "Completed training batch 764 Training Loss is: 0.1304 Validation Loss is: 0.1425 Accuracy is 97 %\n",
            "Completed training batch 765 Training Loss is: 0.1304 Validation Loss is: 0.1424 Accuracy is 97 %\n",
            "Completed training batch 766 Training Loss is: 0.1303 Validation Loss is: 0.1423 Accuracy is 97 %\n",
            "Completed training batch 767 Training Loss is: 0.1302 Validation Loss is: 0.1423 Accuracy is 97 %\n",
            "Completed training batch 768 Training Loss is: 0.1302 Validation Loss is: 0.1422 Accuracy is 97 %\n",
            "Completed training batch 769 Training Loss is: 0.1301 Validation Loss is: 0.1421 Accuracy is 97 %\n",
            "Completed training batch 770 Training Loss is: 0.1300 Validation Loss is: 0.1421 Accuracy is 97 %\n",
            "Completed training batch 771 Training Loss is: 0.1300 Validation Loss is: 0.1420 Accuracy is 97 %\n",
            "Completed training batch 772 Training Loss is: 0.1299 Validation Loss is: 0.1419 Accuracy is 97 %\n",
            "Completed training batch 773 Training Loss is: 0.1298 Validation Loss is: 0.1419 Accuracy is 97 %\n",
            "Completed training batch 774 Training Loss is: 0.1298 Validation Loss is: 0.1418 Accuracy is 97 %\n",
            "Completed training batch 775 Training Loss is: 0.1297 Validation Loss is: 0.1417 Accuracy is 97 %\n",
            "Completed training batch 776 Training Loss is: 0.1297 Validation Loss is: 0.1417 Accuracy is 97 %\n",
            "Completed training batch 777 Training Loss is: 0.1296 Validation Loss is: 0.1416 Accuracy is 97 %\n",
            "Completed training batch 778 Training Loss is: 0.1295 Validation Loss is: 0.1415 Accuracy is 97 %\n",
            "Completed training batch 779 Training Loss is: 0.1295 Validation Loss is: 0.1415 Accuracy is 97 %\n",
            "Completed training batch 780 Training Loss is: 0.1294 Validation Loss is: 0.1414 Accuracy is 97 %\n",
            "Completed training batch 781 Training Loss is: 0.1293 Validation Loss is: 0.1413 Accuracy is 97 %\n",
            "Completed training batch 782 Training Loss is: 0.1293 Validation Loss is: 0.1413 Accuracy is 97 %\n",
            "Completed training batch 783 Training Loss is: 0.1292 Validation Loss is: 0.1412 Accuracy is 97 %\n",
            "Completed training batch 784 Training Loss is: 0.1291 Validation Loss is: 0.1411 Accuracy is 97 %\n",
            "Completed training batch 785 Training Loss is: 0.1291 Validation Loss is: 0.1411 Accuracy is 97 %\n",
            "Completed training batch 786 Training Loss is: 0.1290 Validation Loss is: 0.1410 Accuracy is 97 %\n",
            "Completed training batch 787 Training Loss is: 0.1290 Validation Loss is: 0.1409 Accuracy is 97 %\n",
            "Completed training batch 788 Training Loss is: 0.1289 Validation Loss is: 0.1409 Accuracy is 97 %\n",
            "Completed training batch 789 Training Loss is: 0.1288 Validation Loss is: 0.1408 Accuracy is 97 %\n",
            "Completed training batch 790 Training Loss is: 0.1288 Validation Loss is: 0.1407 Accuracy is 97 %\n",
            "Completed training batch 791 Training Loss is: 0.1287 Validation Loss is: 0.1407 Accuracy is 97 %\n",
            "Completed training batch 792 Training Loss is: 0.1286 Validation Loss is: 0.1406 Accuracy is 97 %\n",
            "Completed training batch 793 Training Loss is: 0.1286 Validation Loss is: 0.1405 Accuracy is 97 %\n",
            "Completed training batch 794 Training Loss is: 0.1285 Validation Loss is: 0.1405 Accuracy is 97 %\n",
            "Completed training batch 795 Training Loss is: 0.1285 Validation Loss is: 0.1404 Accuracy is 97 %\n",
            "Completed training batch 796 Training Loss is: 0.1284 Validation Loss is: 0.1403 Accuracy is 97 %\n",
            "Completed training batch 797 Training Loss is: 0.1283 Validation Loss is: 0.1403 Accuracy is 97 %\n",
            "Completed training batch 798 Training Loss is: 0.1283 Validation Loss is: 0.1402 Accuracy is 97 %\n",
            "Completed training batch 799 Training Loss is: 0.1282 Validation Loss is: 0.1401 Accuracy is 97 %\n",
            "Completed training batch 800 Training Loss is: 0.1282 Validation Loss is: 0.1401 Accuracy is 97 %\n",
            "Completed training batch 801 Training Loss is: 0.1281 Validation Loss is: 0.1400 Accuracy is 97 %\n",
            "Completed training batch 802 Training Loss is: 0.1280 Validation Loss is: 0.1399 Accuracy is 97 %\n",
            "Completed training batch 803 Training Loss is: 0.1280 Validation Loss is: 0.1399 Accuracy is 97 %\n",
            "Completed training batch 804 Training Loss is: 0.1279 Validation Loss is: 0.1398 Accuracy is 97 %\n",
            "Completed training batch 805 Training Loss is: 0.1279 Validation Loss is: 0.1398 Accuracy is 97 %\n",
            "Completed training batch 806 Training Loss is: 0.1278 Validation Loss is: 0.1397 Accuracy is 97 %\n",
            "Completed training batch 807 Training Loss is: 0.1277 Validation Loss is: 0.1396 Accuracy is 97 %\n",
            "Completed training batch 808 Training Loss is: 0.1277 Validation Loss is: 0.1396 Accuracy is 97 %\n",
            "Completed training batch 809 Training Loss is: 0.1276 Validation Loss is: 0.1395 Accuracy is 97 %\n",
            "Completed training batch 810 Training Loss is: 0.1276 Validation Loss is: 0.1394 Accuracy is 97 %\n",
            "Completed training batch 811 Training Loss is: 0.1275 Validation Loss is: 0.1394 Accuracy is 97 %\n",
            "Completed training batch 812 Training Loss is: 0.1274 Validation Loss is: 0.1393 Accuracy is 97 %\n",
            "Completed training batch 813 Training Loss is: 0.1274 Validation Loss is: 0.1392 Accuracy is 97 %\n",
            "Completed training batch 814 Training Loss is: 0.1273 Validation Loss is: 0.1392 Accuracy is 97 %\n",
            "Completed training batch 815 Training Loss is: 0.1273 Validation Loss is: 0.1391 Accuracy is 97 %\n",
            "Completed training batch 816 Training Loss is: 0.1272 Validation Loss is: 0.1391 Accuracy is 97 %\n",
            "Completed training batch 817 Training Loss is: 0.1271 Validation Loss is: 0.1390 Accuracy is 97 %\n",
            "Completed training batch 818 Training Loss is: 0.1271 Validation Loss is: 0.1389 Accuracy is 97 %\n",
            "Completed training batch 819 Training Loss is: 0.1270 Validation Loss is: 0.1389 Accuracy is 97 %\n",
            "Completed training batch 820 Training Loss is: 0.1270 Validation Loss is: 0.1388 Accuracy is 97 %\n",
            "Completed training batch 821 Training Loss is: 0.1269 Validation Loss is: 0.1387 Accuracy is 97 %\n",
            "Completed training batch 822 Training Loss is: 0.1268 Validation Loss is: 0.1387 Accuracy is 97 %\n",
            "Completed training batch 823 Training Loss is: 0.1268 Validation Loss is: 0.1386 Accuracy is 97 %\n",
            "Completed training batch 824 Training Loss is: 0.1267 Validation Loss is: 0.1386 Accuracy is 97 %\n",
            "Completed training batch 825 Training Loss is: 0.1267 Validation Loss is: 0.1385 Accuracy is 97 %\n",
            "Completed training batch 826 Training Loss is: 0.1266 Validation Loss is: 0.1384 Accuracy is 97 %\n",
            "Completed training batch 827 Training Loss is: 0.1266 Validation Loss is: 0.1384 Accuracy is 97 %\n",
            "Completed training batch 828 Training Loss is: 0.1265 Validation Loss is: 0.1383 Accuracy is 97 %\n",
            "Completed training batch 829 Training Loss is: 0.1264 Validation Loss is: 0.1383 Accuracy is 97 %\n",
            "Completed training batch 830 Training Loss is: 0.1264 Validation Loss is: 0.1382 Accuracy is 97 %\n",
            "Completed training batch 831 Training Loss is: 0.1263 Validation Loss is: 0.1381 Accuracy is 97 %\n",
            "Completed training batch 832 Training Loss is: 0.1263 Validation Loss is: 0.1381 Accuracy is 97 %\n",
            "Completed training batch 833 Training Loss is: 0.1262 Validation Loss is: 0.1380 Accuracy is 97 %\n",
            "Completed training batch 834 Training Loss is: 0.1262 Validation Loss is: 0.1380 Accuracy is 97 %\n",
            "Completed training batch 835 Training Loss is: 0.1261 Validation Loss is: 0.1379 Accuracy is 97 %\n",
            "Completed training batch 836 Training Loss is: 0.1260 Validation Loss is: 0.1378 Accuracy is 97 %\n",
            "Completed training batch 837 Training Loss is: 0.1260 Validation Loss is: 0.1378 Accuracy is 97 %\n",
            "Completed training batch 838 Training Loss is: 0.1259 Validation Loss is: 0.1377 Accuracy is 97 %\n",
            "Completed training batch 839 Training Loss is: 0.1259 Validation Loss is: 0.1377 Accuracy is 97 %\n",
            "Completed training batch 840 Training Loss is: 0.1258 Validation Loss is: 0.1376 Accuracy is 97 %\n",
            "Completed training batch 841 Training Loss is: 0.1258 Validation Loss is: 0.1375 Accuracy is 97 %\n",
            "Completed training batch 842 Training Loss is: 0.1257 Validation Loss is: 0.1375 Accuracy is 97 %\n",
            "Completed training batch 843 Training Loss is: 0.1256 Validation Loss is: 0.1374 Accuracy is 97 %\n",
            "Completed training batch 844 Training Loss is: 0.1256 Validation Loss is: 0.1374 Accuracy is 97 %\n",
            "Completed training batch 845 Training Loss is: 0.1255 Validation Loss is: 0.1373 Accuracy is 97 %\n",
            "Completed training batch 846 Training Loss is: 0.1255 Validation Loss is: 0.1372 Accuracy is 97 %\n",
            "Completed training batch 847 Training Loss is: 0.1254 Validation Loss is: 0.1372 Accuracy is 97 %\n",
            "Completed training batch 848 Training Loss is: 0.1254 Validation Loss is: 0.1371 Accuracy is 97 %\n",
            "Completed training batch 849 Training Loss is: 0.1253 Validation Loss is: 0.1371 Accuracy is 97 %\n",
            "Completed training batch 850 Training Loss is: 0.1253 Validation Loss is: 0.1370 Accuracy is 97 %\n",
            "Completed training batch 851 Training Loss is: 0.1252 Validation Loss is: 0.1369 Accuracy is 97 %\n",
            "Completed training batch 852 Training Loss is: 0.1251 Validation Loss is: 0.1369 Accuracy is 97 %\n",
            "Completed training batch 853 Training Loss is: 0.1251 Validation Loss is: 0.1368 Accuracy is 97 %\n",
            "Completed training batch 854 Training Loss is: 0.1250 Validation Loss is: 0.1368 Accuracy is 97 %\n",
            "Completed training batch 855 Training Loss is: 0.1250 Validation Loss is: 0.1367 Accuracy is 97 %\n",
            "Completed training batch 856 Training Loss is: 0.1249 Validation Loss is: 0.1367 Accuracy is 97 %\n",
            "Completed training batch 857 Training Loss is: 0.1249 Validation Loss is: 0.1366 Accuracy is 97 %\n",
            "Completed training batch 858 Training Loss is: 0.1248 Validation Loss is: 0.1365 Accuracy is 97 %\n",
            "Completed training batch 859 Training Loss is: 0.1248 Validation Loss is: 0.1365 Accuracy is 97 %\n",
            "Completed training batch 860 Training Loss is: 0.1247 Validation Loss is: 0.1364 Accuracy is 97 %\n",
            "Completed training batch 861 Training Loss is: 0.1246 Validation Loss is: 0.1364 Accuracy is 97 %\n",
            "Completed training batch 862 Training Loss is: 0.1246 Validation Loss is: 0.1363 Accuracy is 97 %\n",
            "Completed training batch 863 Training Loss is: 0.1245 Validation Loss is: 0.1362 Accuracy is 97 %\n",
            "Completed training batch 864 Training Loss is: 0.1245 Validation Loss is: 0.1362 Accuracy is 97 %\n",
            "Completed training batch 865 Training Loss is: 0.1244 Validation Loss is: 0.1361 Accuracy is 97 %\n",
            "Completed training batch 866 Training Loss is: 0.1244 Validation Loss is: 0.1361 Accuracy is 97 %\n",
            "Completed training batch 867 Training Loss is: 0.1243 Validation Loss is: 0.1360 Accuracy is 97 %\n",
            "Completed training batch 868 Training Loss is: 0.1243 Validation Loss is: 0.1360 Accuracy is 97 %\n",
            "Completed training batch 869 Training Loss is: 0.1242 Validation Loss is: 0.1359 Accuracy is 97 %\n",
            "Completed training batch 870 Training Loss is: 0.1242 Validation Loss is: 0.1358 Accuracy is 97 %\n",
            "Completed training batch 871 Training Loss is: 0.1241 Validation Loss is: 0.1358 Accuracy is 97 %\n",
            "Completed training batch 872 Training Loss is: 0.1241 Validation Loss is: 0.1357 Accuracy is 97 %\n",
            "Completed training batch 873 Training Loss is: 0.1240 Validation Loss is: 0.1357 Accuracy is 97 %\n",
            "Completed training batch 874 Training Loss is: 0.1239 Validation Loss is: 0.1356 Accuracy is 97 %\n",
            "Completed training batch 875 Training Loss is: 0.1239 Validation Loss is: 0.1356 Accuracy is 97 %\n",
            "Completed training batch 876 Training Loss is: 0.1238 Validation Loss is: 0.1355 Accuracy is 97 %\n",
            "Completed training batch 877 Training Loss is: 0.1238 Validation Loss is: 0.1355 Accuracy is 97 %\n",
            "Completed training batch 878 Training Loss is: 0.1237 Validation Loss is: 0.1354 Accuracy is 97 %\n",
            "Completed training batch 879 Training Loss is: 0.1237 Validation Loss is: 0.1353 Accuracy is 97 %\n",
            "Completed training batch 880 Training Loss is: 0.1236 Validation Loss is: 0.1353 Accuracy is 97 %\n",
            "Completed training batch 881 Training Loss is: 0.1236 Validation Loss is: 0.1352 Accuracy is 97 %\n",
            "Completed training batch 882 Training Loss is: 0.1235 Validation Loss is: 0.1352 Accuracy is 97 %\n",
            "Completed training batch 883 Training Loss is: 0.1235 Validation Loss is: 0.1351 Accuracy is 97 %\n",
            "Completed training batch 884 Training Loss is: 0.1234 Validation Loss is: 0.1351 Accuracy is 97 %\n",
            "Completed training batch 885 Training Loss is: 0.1234 Validation Loss is: 0.1350 Accuracy is 97 %\n",
            "Completed training batch 886 Training Loss is: 0.1233 Validation Loss is: 0.1350 Accuracy is 97 %\n",
            "Completed training batch 887 Training Loss is: 0.1233 Validation Loss is: 0.1349 Accuracy is 97 %\n",
            "Completed training batch 888 Training Loss is: 0.1232 Validation Loss is: 0.1348 Accuracy is 97 %\n",
            "Completed training batch 889 Training Loss is: 0.1232 Validation Loss is: 0.1348 Accuracy is 97 %\n",
            "Completed training batch 890 Training Loss is: 0.1231 Validation Loss is: 0.1347 Accuracy is 97 %\n",
            "Completed training batch 891 Training Loss is: 0.1231 Validation Loss is: 0.1347 Accuracy is 97 %\n",
            "Completed training batch 892 Training Loss is: 0.1230 Validation Loss is: 0.1346 Accuracy is 97 %\n",
            "Completed training batch 893 Training Loss is: 0.1230 Validation Loss is: 0.1346 Accuracy is 97 %\n",
            "Completed training batch 894 Training Loss is: 0.1229 Validation Loss is: 0.1345 Accuracy is 97 %\n",
            "Completed training batch 895 Training Loss is: 0.1229 Validation Loss is: 0.1345 Accuracy is 97 %\n",
            "Completed training batch 896 Training Loss is: 0.1228 Validation Loss is: 0.1344 Accuracy is 97 %\n",
            "Completed training batch 897 Training Loss is: 0.1227 Validation Loss is: 0.1344 Accuracy is 97 %\n",
            "Completed training batch 898 Training Loss is: 0.1227 Validation Loss is: 0.1343 Accuracy is 97 %\n",
            "Completed training batch 899 Training Loss is: 0.1226 Validation Loss is: 0.1343 Accuracy is 97 %\n",
            "Completed training batch 900 Training Loss is: 0.1226 Validation Loss is: 0.1342 Accuracy is 97 %\n",
            "Completed training batch 901 Training Loss is: 0.1225 Validation Loss is: 0.1341 Accuracy is 97 %\n",
            "Completed training batch 902 Training Loss is: 0.1225 Validation Loss is: 0.1341 Accuracy is 97 %\n",
            "Completed training batch 903 Training Loss is: 0.1224 Validation Loss is: 0.1340 Accuracy is 97 %\n",
            "Completed training batch 904 Training Loss is: 0.1224 Validation Loss is: 0.1340 Accuracy is 97 %\n",
            "Completed training batch 905 Training Loss is: 0.1223 Validation Loss is: 0.1339 Accuracy is 97 %\n",
            "Completed training batch 906 Training Loss is: 0.1223 Validation Loss is: 0.1339 Accuracy is 97 %\n",
            "Completed training batch 907 Training Loss is: 0.1222 Validation Loss is: 0.1338 Accuracy is 97 %\n",
            "Completed training batch 908 Training Loss is: 0.1222 Validation Loss is: 0.1338 Accuracy is 97 %\n",
            "Completed training batch 909 Training Loss is: 0.1221 Validation Loss is: 0.1337 Accuracy is 97 %\n",
            "Completed training batch 910 Training Loss is: 0.1221 Validation Loss is: 0.1337 Accuracy is 97 %\n",
            "Completed training batch 911 Training Loss is: 0.1220 Validation Loss is: 0.1336 Accuracy is 97 %\n",
            "Completed training batch 912 Training Loss is: 0.1220 Validation Loss is: 0.1336 Accuracy is 97 %\n",
            "Completed training batch 913 Training Loss is: 0.1219 Validation Loss is: 0.1335 Accuracy is 97 %\n",
            "Completed training batch 914 Training Loss is: 0.1219 Validation Loss is: 0.1335 Accuracy is 97 %\n",
            "Completed training batch 915 Training Loss is: 0.1218 Validation Loss is: 0.1334 Accuracy is 97 %\n",
            "Completed training batch 916 Training Loss is: 0.1218 Validation Loss is: 0.1333 Accuracy is 97 %\n",
            "Completed training batch 917 Training Loss is: 0.1217 Validation Loss is: 0.1333 Accuracy is 97 %\n",
            "Completed training batch 918 Training Loss is: 0.1217 Validation Loss is: 0.1332 Accuracy is 97 %\n",
            "Completed training batch 919 Training Loss is: 0.1216 Validation Loss is: 0.1332 Accuracy is 97 %\n",
            "Completed training batch 920 Training Loss is: 0.1216 Validation Loss is: 0.1331 Accuracy is 97 %\n",
            "Completed training batch 921 Training Loss is: 0.1215 Validation Loss is: 0.1331 Accuracy is 97 %\n",
            "Completed training batch 922 Training Loss is: 0.1215 Validation Loss is: 0.1330 Accuracy is 97 %\n",
            "Completed training batch 923 Training Loss is: 0.1214 Validation Loss is: 0.1330 Accuracy is 97 %\n",
            "Completed training batch 924 Training Loss is: 0.1214 Validation Loss is: 0.1329 Accuracy is 97 %\n",
            "Completed training batch 925 Training Loss is: 0.1213 Validation Loss is: 0.1329 Accuracy is 97 %\n",
            "Completed training batch 926 Training Loss is: 0.1213 Validation Loss is: 0.1328 Accuracy is 97 %\n",
            "Completed training batch 927 Training Loss is: 0.1213 Validation Loss is: 0.1328 Accuracy is 97 %\n",
            "Completed training batch 928 Training Loss is: 0.1212 Validation Loss is: 0.1327 Accuracy is 97 %\n",
            "Completed training batch 929 Training Loss is: 0.1212 Validation Loss is: 0.1327 Accuracy is 97 %\n",
            "Completed training batch 930 Training Loss is: 0.1211 Validation Loss is: 0.1326 Accuracy is 97 %\n",
            "Completed training batch 931 Training Loss is: 0.1211 Validation Loss is: 0.1326 Accuracy is 97 %\n",
            "Completed training batch 932 Training Loss is: 0.1210 Validation Loss is: 0.1325 Accuracy is 97 %\n",
            "Completed training batch 933 Training Loss is: 0.1210 Validation Loss is: 0.1325 Accuracy is 97 %\n",
            "Completed training batch 934 Training Loss is: 0.1209 Validation Loss is: 0.1324 Accuracy is 97 %\n",
            "Completed training batch 935 Training Loss is: 0.1209 Validation Loss is: 0.1324 Accuracy is 97 %\n",
            "Completed training batch 936 Training Loss is: 0.1208 Validation Loss is: 0.1323 Accuracy is 97 %\n",
            "Completed training batch 937 Training Loss is: 0.1208 Validation Loss is: 0.1323 Accuracy is 97 %\n",
            "Completed training batch 938 Training Loss is: 0.1207 Validation Loss is: 0.1322 Accuracy is 97 %\n",
            "Completed training batch 939 Training Loss is: 0.1207 Validation Loss is: 0.1322 Accuracy is 97 %\n",
            "Completed training batch 940 Training Loss is: 0.1206 Validation Loss is: 0.1321 Accuracy is 97 %\n",
            "Completed training batch 941 Training Loss is: 0.1206 Validation Loss is: 0.1321 Accuracy is 97 %\n",
            "Completed training batch 942 Training Loss is: 0.1205 Validation Loss is: 0.1320 Accuracy is 97 %\n",
            "Completed training batch 943 Training Loss is: 0.1205 Validation Loss is: 0.1320 Accuracy is 97 %\n",
            "Completed training batch 944 Training Loss is: 0.1204 Validation Loss is: 0.1319 Accuracy is 97 %\n",
            "Completed training batch 945 Training Loss is: 0.1204 Validation Loss is: 0.1319 Accuracy is 97 %\n",
            "Completed training batch 946 Training Loss is: 0.1203 Validation Loss is: 0.1318 Accuracy is 97 %\n",
            "Completed training batch 947 Training Loss is: 0.1203 Validation Loss is: 0.1318 Accuracy is 97 %\n",
            "Completed training batch 948 Training Loss is: 0.1202 Validation Loss is: 0.1317 Accuracy is 97 %\n",
            "Completed training batch 949 Training Loss is: 0.1202 Validation Loss is: 0.1317 Accuracy is 97 %\n",
            "Completed training batch 950 Training Loss is: 0.1202 Validation Loss is: 0.1316 Accuracy is 97 %\n",
            "Completed training batch 951 Training Loss is: 0.1201 Validation Loss is: 0.1316 Accuracy is 97 %\n",
            "Completed training batch 952 Training Loss is: 0.1201 Validation Loss is: 0.1315 Accuracy is 97 %\n",
            "Completed training batch 953 Training Loss is: 0.1200 Validation Loss is: 0.1315 Accuracy is 97 %\n",
            "Completed training batch 954 Training Loss is: 0.1200 Validation Loss is: 0.1314 Accuracy is 97 %\n",
            "Completed training batch 955 Training Loss is: 0.1199 Validation Loss is: 0.1314 Accuracy is 97 %\n",
            "Completed training batch 956 Training Loss is: 0.1199 Validation Loss is: 0.1313 Accuracy is 97 %\n",
            "Completed training batch 957 Training Loss is: 0.1198 Validation Loss is: 0.1313 Accuracy is 97 %\n",
            "Completed training batch 958 Training Loss is: 0.1198 Validation Loss is: 0.1312 Accuracy is 97 %\n",
            "Completed training batch 959 Training Loss is: 0.1197 Validation Loss is: 0.1312 Accuracy is 97 %\n",
            "Completed training batch 960 Training Loss is: 0.1197 Validation Loss is: 0.1311 Accuracy is 97 %\n",
            "Completed training batch 961 Training Loss is: 0.1196 Validation Loss is: 0.1311 Accuracy is 97 %\n",
            "Completed training batch 962 Training Loss is: 0.1196 Validation Loss is: 0.1310 Accuracy is 97 %\n",
            "Completed training batch 963 Training Loss is: 0.1195 Validation Loss is: 0.1310 Accuracy is 97 %\n",
            "Completed training batch 964 Training Loss is: 0.1195 Validation Loss is: 0.1309 Accuracy is 97 %\n",
            "Completed training batch 965 Training Loss is: 0.1195 Validation Loss is: 0.1309 Accuracy is 97 %\n",
            "Completed training batch 966 Training Loss is: 0.1194 Validation Loss is: 0.1308 Accuracy is 97 %\n",
            "Completed training batch 967 Training Loss is: 0.1194 Validation Loss is: 0.1308 Accuracy is 97 %\n",
            "Completed training batch 968 Training Loss is: 0.1193 Validation Loss is: 0.1307 Accuracy is 97 %\n",
            "Completed training batch 969 Training Loss is: 0.1193 Validation Loss is: 0.1307 Accuracy is 97 %\n",
            "Completed training batch 970 Training Loss is: 0.1192 Validation Loss is: 0.1307 Accuracy is 97 %\n",
            "Completed training batch 971 Training Loss is: 0.1192 Validation Loss is: 0.1306 Accuracy is 97 %\n",
            "Completed training batch 972 Training Loss is: 0.1191 Validation Loss is: 0.1306 Accuracy is 97 %\n",
            "Completed training batch 973 Training Loss is: 0.1191 Validation Loss is: 0.1305 Accuracy is 97 %\n",
            "Completed training batch 974 Training Loss is: 0.1190 Validation Loss is: 0.1305 Accuracy is 97 %\n",
            "Completed training batch 975 Training Loss is: 0.1190 Validation Loss is: 0.1304 Accuracy is 97 %\n",
            "Completed training batch 976 Training Loss is: 0.1190 Validation Loss is: 0.1304 Accuracy is 97 %\n",
            "Completed training batch 977 Training Loss is: 0.1189 Validation Loss is: 0.1303 Accuracy is 97 %\n",
            "Completed training batch 978 Training Loss is: 0.1189 Validation Loss is: 0.1303 Accuracy is 97 %\n",
            "Completed training batch 979 Training Loss is: 0.1188 Validation Loss is: 0.1302 Accuracy is 97 %\n",
            "Completed training batch 980 Training Loss is: 0.1188 Validation Loss is: 0.1302 Accuracy is 97 %\n",
            "Completed training batch 981 Training Loss is: 0.1187 Validation Loss is: 0.1301 Accuracy is 97 %\n",
            "Completed training batch 982 Training Loss is: 0.1187 Validation Loss is: 0.1301 Accuracy is 97 %\n",
            "Completed training batch 983 Training Loss is: 0.1186 Validation Loss is: 0.1300 Accuracy is 97 %\n",
            "Completed training batch 984 Training Loss is: 0.1186 Validation Loss is: 0.1300 Accuracy is 97 %\n",
            "Completed training batch 985 Training Loss is: 0.1186 Validation Loss is: 0.1299 Accuracy is 97 %\n",
            "Completed training batch 986 Training Loss is: 0.1185 Validation Loss is: 0.1299 Accuracy is 97 %\n",
            "Completed training batch 987 Training Loss is: 0.1185 Validation Loss is: 0.1298 Accuracy is 97 %\n",
            "Completed training batch 988 Training Loss is: 0.1184 Validation Loss is: 0.1298 Accuracy is 97 %\n",
            "Completed training batch 989 Training Loss is: 0.1184 Validation Loss is: 0.1298 Accuracy is 97 %\n",
            "Completed training batch 990 Training Loss is: 0.1183 Validation Loss is: 0.1297 Accuracy is 97 %\n",
            "Completed training batch 991 Training Loss is: 0.1183 Validation Loss is: 0.1297 Accuracy is 97 %\n",
            "Completed training batch 992 Training Loss is: 0.1182 Validation Loss is: 0.1296 Accuracy is 97 %\n",
            "Completed training batch 993 Training Loss is: 0.1182 Validation Loss is: 0.1296 Accuracy is 97 %\n",
            "Completed training batch 994 Training Loss is: 0.1182 Validation Loss is: 0.1295 Accuracy is 97 %\n",
            "Completed training batch 995 Training Loss is: 0.1181 Validation Loss is: 0.1295 Accuracy is 97 %\n",
            "Completed training batch 996 Training Loss is: 0.1181 Validation Loss is: 0.1294 Accuracy is 97 %\n",
            "Completed training batch 997 Training Loss is: 0.1180 Validation Loss is: 0.1294 Accuracy is 97 %\n",
            "Completed training batch 998 Training Loss is: 0.1180 Validation Loss is: 0.1293 Accuracy is 97 %\n",
            "Completed training batch 999 Training Loss is: 0.1179 Validation Loss is: 0.1293 Accuracy is 97 %\n",
            "Completed training batch 1000 Training Loss is: 0.1179 Validation Loss is: 0.1293 Accuracy is 97 %\n",
            "Finished Training\n",
            "\n",
            "Test Accuracy is: 93 %\n"
          ]
        }
      ]
    }
  ]
}