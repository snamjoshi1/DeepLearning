{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_mlp (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {
        "id": "VmbGIjy-9hBx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Seed 1\n",
        "#torch.manual_seed(32)\n",
        "#random.seed(60)\n",
        "#np.random.seed(1)\n",
        "\n",
        "#Seed 2\n",
        "#torch.manual_seed(29)\n",
        "#random.seed(55)\n",
        "#np.random.seed(0)\n",
        "\n",
        "#Seed 3\n",
        "torch.manual_seed(94)\n",
        "random.seed(61)\n",
        "np.random.seed(2)\n",
        "\n",
        "torch.use_deterministic_algorithms(True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch as t\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "OyC_e2dU9jlG"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import TensorDataset\n",
        "# choose the training and test datasets\n",
        "iris_train_load=pd.read_csv('/content/iris_training.csv',header=None)\n",
        "iris_train_load\n",
        "\n",
        "\n",
        "input=iris_train_load.iloc[:,:4]\n",
        "print('\\nInput values are:') \n",
        "print(input.head())\n",
        "\n",
        "output=iris_train_load.iloc[:,4:5]\n",
        "print('\\nThe output value is:') \n",
        "print(output.head()) \n",
        "\n",
        "\n",
        "# Convert Input and Output data to Tensors and create a TensorDataset \n",
        "input = torch.Tensor(input.to_numpy())      # Create tensor of type torch.float32 \n",
        "print('\\nInput format: ', input.shape, input.dtype)     # Input format: torch.Size([120, 4]) torch.float32 \n",
        "output = torch.tensor(output.to_numpy())        # Create tensor type torch.int64  \n",
        "print('Output format: ', output.shape, output.dtype)  # Output format: torch.Size([120, 1]) torch.int64 \n",
        "data_train = TensorDataset(input, output)  \n",
        "\n",
        "\n",
        "iris_test_load=pd.read_csv('/content/iris_test.csv',header=None)\n",
        "input_test=iris_test_load.iloc[:,:4]\n",
        "print('\\nInput values are:') \n",
        "print(input_test.head())\n",
        "\n",
        "output_test=iris_test_load.iloc[:,4:5]\n",
        "print('\\nThe output value is:') \n",
        "print(output_test.head()) \n",
        "\n",
        "\n",
        "# Convert Input and Output data to Tensors and create a TensorDataset \n",
        "input_test = torch.Tensor(input_test.to_numpy())      # Create tensor of type torch.float32 \n",
        "print('\\nInput format: ', input_test.shape, input_test.dtype)     # Input format: torch.Size([30, 4]) torch.float32 \n",
        "output_test = torch.tensor(output_test.to_numpy())        # Create tensor type torch.int64  \n",
        "print('Output format: ', output_test.shape, output_test.dtype)  # Output format: torch.Size([30, ]) torch.int64 \n",
        "data_test = TensorDataset(input_test, output_test)  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgeZYDAs9uns",
        "outputId": "c2484eae-3234-4d79-f989-27b418a34b8a"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input values are:\n",
            "     0    1    2    3\n",
            "0  6.4  2.8  5.6  2.2\n",
            "1  5.0  2.3  3.3  1.0\n",
            "2  4.9  2.5  4.5  1.7\n",
            "3  4.9  3.1  1.5  0.1\n",
            "4  5.7  3.8  1.7  0.3\n",
            "\n",
            "The output value is:\n",
            "   4\n",
            "0  2\n",
            "1  1\n",
            "2  2\n",
            "3  0\n",
            "4  0\n",
            "\n",
            "Input format:  torch.Size([120, 4]) torch.float32\n",
            "Output format:  torch.Size([120, 1]) torch.int64\n",
            "\n",
            "Input values are:\n",
            "     0    1    2    3\n",
            "0  5.9  3.0  4.2  1.5\n",
            "1  6.9  3.1  5.4  2.1\n",
            "2  5.1  3.3  1.7  0.5\n",
            "3  6.0  3.4  4.5  1.6\n",
            "4  5.5  2.5  4.0  1.3\n",
            "\n",
            "The output value is:\n",
            "   4\n",
            "0  1\n",
            "1  2\n",
            "2  0\n",
            "3  1\n",
            "4  1\n",
            "\n",
            "Input format:  torch.Size([30, 4]) torch.float32\n",
            "Output format:  torch.Size([30, 1]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 10\n",
        "number_rows = len(input)    # The size of our dataset or the number of rows in excel table.  \n",
        "val_split = int(number_rows*0.3)  \n",
        "train_split = number_rows - val_split   \n",
        "train_set, validate_set= torch.utils.data.random_split( \n",
        "    data_train, [train_split, val_split])    \n",
        " \n",
        "# Create Dataloader to read the data within batch sizes and put into memory. \n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=train_batch_size ) \n",
        "validate_loader = torch.utils.data.DataLoader(validate_set,batch_size=1) \n",
        "test_loader = torch.utils.data.DataLoader(data_test,batch_size=1)"
      ],
      "metadata": {
        "id": "9Fg9LOkIeq-q"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the NN architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 5)        # linear layer 1\n",
        "        self.fc2 = nn.Linear(5, 10)       # linear layer 2\n",
        "        self.fc3 = nn.Linear(10, 5)       # linear layer 3\n",
        "        self.fc4 = nn.Linear(5, 3)        # linear layer (3_hidden -> 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3UCPGl7MXRo",
        "outputId": "4c1040e8-1816-4d18-aaef-006b2db08e03"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=4, out_features=5, bias=True)\n",
            "  (fc2): Linear(in_features=5, out_features=10, bias=True)\n",
            "  (fc3): Linear(in_features=10, out_features=5, bias=True)\n",
            "  (fc4): Linear(in_features=5, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Specify loss and optimization functions\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "print(criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I5lFSxoN8uw",
        "outputId": "9538de25-9521-4a51-8cb4-e73b6aa7fc2e"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrossEntropyLoss() SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.05\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function \n",
        "def train(num_epochs): \n",
        "    best_accuracy = 0.0 \n",
        "     \n",
        "    print(\"Begin training...\") \n",
        "    for epoch in range(1, num_epochs+1): \n",
        "        running_train_loss = 0.0 \n",
        "        running_accuracy = 0.0 \n",
        "        running_vall_loss = 0.0 \n",
        "        total = 0 \n",
        " \n",
        "        # Training Loop \n",
        "        for data in train_loader: \n",
        "        #for data in enumerate(train_loader, 0): \n",
        "            inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs] \n",
        "            optimizer.zero_grad()   # zero the parameter gradients          \n",
        "            predicted_outputs = model(inputs)   # predict output from the model \n",
        "            train_loss = criterion(predicted_outputs, torch.flatten(outputs))   # calculate loss for the predicted output  \n",
        "            train_loss.backward()   # backpropagate the loss \n",
        "            optimizer.step()        # adjust parameters based on the calculated gradients \n",
        "            running_train_loss +=train_loss.item()  # track the loss value \n",
        " \n",
        "        # Calculate training loss value \n",
        "        train_loss_value = running_train_loss/len(train_loader) \n",
        " \n",
        "        # Validation Loop \n",
        "        with torch.no_grad(): \n",
        "            model.eval() \n",
        "            for data in validate_loader: \n",
        "                inputs, outputs = data \n",
        "                predicted_outputs = model(inputs) \n",
        "                val_loss = criterion(predicted_outputs, torch.flatten(outputs)) \n",
        "             \n",
        "               # The label with the highest value will be our prediction \n",
        "                _, predicted = torch.max(predicted_outputs, 1) \n",
        "                running_vall_loss += val_loss.item()  \n",
        "                total += outputs.size(0) \n",
        "                running_accuracy += (predicted.eq(torch.flatten(outputs))).sum().item() \n",
        "\n",
        " \n",
        "        # Calculate validation loss value \n",
        "        val_loss_value = running_vall_loss/len(validate_loader) \n",
        "                \n",
        "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
        "        accuracy = (100 * running_accuracy / total)     \n",
        "\n",
        "         \n",
        "        # Print the statistics of the epoch \n",
        "        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))\n",
        "        ## break"
      ],
      "metadata": {
        "id": "cYMGtq1pn-YM"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test the model \n",
        "def test(): \n",
        "    total=0.0\n",
        "    running_accuracy=0.0\n",
        "    with torch.no_grad(): \n",
        "        for data in test_loader: \n",
        "            inputs, outputs = data \n",
        "            outputs = outputs.to(torch.float32) \n",
        "            predicted_outputs = model(inputs) \n",
        "            _, predicted = torch.max(predicted_outputs, 1) \n",
        "            total += outputs.size(0) \n",
        "            running_accuracy += (predicted == torch.flatten(outputs)).sum().item() \n",
        " \n",
        "        print('Test Accuracy is: %d %%' % (100 * running_accuracy / total))    \n",
        " "
      ],
      "metadata": {
        "id": "XXbWJ4Sb5Jhh"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": \n",
        "    num_epochs = 150\n",
        "    train(num_epochs) \n",
        "    print('Finished Training\\n') \n",
        "    test() \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSe_dGKqoKec",
        "outputId": "02d3e6b0-cff2-4059-e191-08738300f308"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin training...\n",
            "Completed training batch 1 Training Loss is: 1.1195 Validation Loss is: 1.1099 Accuracy is 33 %\n",
            "Completed training batch 2 Training Loss is: 1.1033 Validation Loss is: 1.0994 Accuracy is 50 %\n",
            "Completed training batch 3 Training Loss is: 1.0899 Validation Loss is: 1.0905 Accuracy is 30 %\n",
            "Completed training batch 4 Training Loss is: 1.0775 Validation Loss is: 1.0817 Accuracy is 30 %\n",
            "Completed training batch 5 Training Loss is: 1.0647 Validation Loss is: 1.0722 Accuracy is 30 %\n",
            "Completed training batch 6 Training Loss is: 1.0506 Validation Loss is: 1.0612 Accuracy is 30 %\n",
            "Completed training batch 7 Training Loss is: 1.0342 Validation Loss is: 1.0472 Accuracy is 30 %\n",
            "Completed training batch 8 Training Loss is: 1.0141 Validation Loss is: 1.0293 Accuracy is 30 %\n",
            "Completed training batch 9 Training Loss is: 0.9886 Validation Loss is: 1.0033 Accuracy is 30 %\n",
            "Completed training batch 10 Training Loss is: 0.9513 Validation Loss is: 0.9539 Accuracy is 66 %\n",
            "Completed training batch 11 Training Loss is: 0.8916 Validation Loss is: 0.9062 Accuracy is 66 %\n",
            "Completed training batch 12 Training Loss is: 0.8428 Validation Loss is: 0.8689 Accuracy is 66 %\n",
            "Completed training batch 13 Training Loss is: 0.8034 Validation Loss is: 0.8343 Accuracy is 66 %\n",
            "Completed training batch 14 Training Loss is: 0.7686 Validation Loss is: 0.8002 Accuracy is 66 %\n",
            "Completed training batch 15 Training Loss is: 0.7371 Validation Loss is: 0.7683 Accuracy is 66 %\n",
            "Completed training batch 16 Training Loss is: 0.7101 Validation Loss is: 0.7397 Accuracy is 66 %\n",
            "Completed training batch 17 Training Loss is: 0.6866 Validation Loss is: 0.7145 Accuracy is 66 %\n",
            "Completed training batch 18 Training Loss is: 0.6655 Validation Loss is: 0.6929 Accuracy is 66 %\n",
            "Completed training batch 19 Training Loss is: 0.6469 Validation Loss is: 0.6738 Accuracy is 66 %\n",
            "Completed training batch 20 Training Loss is: 0.6304 Validation Loss is: 0.6562 Accuracy is 66 %\n",
            "Completed training batch 21 Training Loss is: 0.6149 Validation Loss is: 0.6398 Accuracy is 66 %\n",
            "Completed training batch 22 Training Loss is: 0.6002 Validation Loss is: 0.6246 Accuracy is 66 %\n",
            "Completed training batch 23 Training Loss is: 0.5860 Validation Loss is: 0.6100 Accuracy is 66 %\n",
            "Completed training batch 24 Training Loss is: 0.5726 Validation Loss is: 0.5959 Accuracy is 66 %\n",
            "Completed training batch 25 Training Loss is: 0.5597 Validation Loss is: 0.5825 Accuracy is 66 %\n",
            "Completed training batch 26 Training Loss is: 0.5471 Validation Loss is: 0.5696 Accuracy is 66 %\n",
            "Completed training batch 27 Training Loss is: 0.5352 Validation Loss is: 0.5570 Accuracy is 66 %\n",
            "Completed training batch 28 Training Loss is: 0.5234 Validation Loss is: 0.5446 Accuracy is 66 %\n",
            "Completed training batch 29 Training Loss is: 0.5118 Validation Loss is: 0.5323 Accuracy is 66 %\n",
            "Completed training batch 30 Training Loss is: 0.5003 Validation Loss is: 0.5201 Accuracy is 66 %\n",
            "Completed training batch 31 Training Loss is: 0.4889 Validation Loss is: 0.5078 Accuracy is 66 %\n",
            "Completed training batch 32 Training Loss is: 0.4776 Validation Loss is: 0.4953 Accuracy is 66 %\n",
            "Completed training batch 33 Training Loss is: 0.4664 Validation Loss is: 0.4827 Accuracy is 69 %\n",
            "Completed training batch 34 Training Loss is: 0.4552 Validation Loss is: 0.4697 Accuracy is 72 %\n",
            "Completed training batch 35 Training Loss is: 0.4442 Validation Loss is: 0.4565 Accuracy is 72 %\n",
            "Completed training batch 36 Training Loss is: 0.4334 Validation Loss is: 0.4431 Accuracy is 75 %\n",
            "Completed training batch 37 Training Loss is: 0.4231 Validation Loss is: 0.4297 Accuracy is 77 %\n",
            "Completed training batch 38 Training Loss is: 0.4137 Validation Loss is: 0.4169 Accuracy is 77 %\n",
            "Completed training batch 39 Training Loss is: 0.4057 Validation Loss is: 0.4072 Accuracy is 77 %\n",
            "Completed training batch 40 Training Loss is: 0.4004 Validation Loss is: 0.3994 Accuracy is 77 %\n",
            "Completed training batch 41 Training Loss is: 0.3984 Validation Loss is: 0.3973 Accuracy is 77 %\n",
            "Completed training batch 42 Training Loss is: 0.4033 Validation Loss is: 0.4016 Accuracy is 77 %\n",
            "Completed training batch 43 Training Loss is: 0.4092 Validation Loss is: 0.4098 Accuracy is 75 %\n",
            "Completed training batch 44 Training Loss is: 0.4175 Validation Loss is: 0.4144 Accuracy is 75 %\n",
            "Completed training batch 45 Training Loss is: 0.4207 Validation Loss is: 0.4130 Accuracy is 75 %\n",
            "Completed training batch 46 Training Loss is: 0.4198 Validation Loss is: 0.4066 Accuracy is 75 %\n",
            "Completed training batch 47 Training Loss is: 0.4167 Validation Loss is: 0.4053 Accuracy is 75 %\n",
            "Completed training batch 48 Training Loss is: 0.4159 Validation Loss is: 0.4032 Accuracy is 75 %\n",
            "Completed training batch 49 Training Loss is: 0.4124 Validation Loss is: 0.4062 Accuracy is 75 %\n",
            "Completed training batch 50 Training Loss is: 0.4188 Validation Loss is: 0.4003 Accuracy is 75 %\n",
            "Completed training batch 51 Training Loss is: 0.4071 Validation Loss is: 0.3981 Accuracy is 75 %\n",
            "Completed training batch 52 Training Loss is: 0.4131 Validation Loss is: 0.3952 Accuracy is 77 %\n",
            "Completed training batch 53 Training Loss is: 0.4105 Validation Loss is: 0.3929 Accuracy is 77 %\n",
            "Completed training batch 54 Training Loss is: 0.4054 Validation Loss is: 0.3908 Accuracy is 77 %\n",
            "Completed training batch 55 Training Loss is: 0.4013 Validation Loss is: 0.3897 Accuracy is 77 %\n",
            "Completed training batch 56 Training Loss is: 0.3971 Validation Loss is: 0.3916 Accuracy is 77 %\n",
            "Completed training batch 57 Training Loss is: 0.3954 Validation Loss is: 0.3926 Accuracy is 77 %\n",
            "Completed training batch 58 Training Loss is: 0.3911 Validation Loss is: 0.3884 Accuracy is 77 %\n",
            "Completed training batch 59 Training Loss is: 0.3858 Validation Loss is: 0.3893 Accuracy is 77 %\n",
            "Completed training batch 60 Training Loss is: 0.3828 Validation Loss is: 0.3914 Accuracy is 77 %\n",
            "Completed training batch 61 Training Loss is: 0.3800 Validation Loss is: 0.3933 Accuracy is 77 %\n",
            "Completed training batch 62 Training Loss is: 0.3817 Validation Loss is: 0.3944 Accuracy is 77 %\n",
            "Completed training batch 63 Training Loss is: 0.3756 Validation Loss is: 0.4015 Accuracy is 77 %\n",
            "Completed training batch 64 Training Loss is: 0.3742 Validation Loss is: 0.4034 Accuracy is 77 %\n",
            "Completed training batch 65 Training Loss is: 0.3677 Validation Loss is: 0.4090 Accuracy is 77 %\n",
            "Completed training batch 66 Training Loss is: 0.3653 Validation Loss is: 0.4138 Accuracy is 77 %\n",
            "Completed training batch 67 Training Loss is: 0.3629 Validation Loss is: 0.4173 Accuracy is 77 %\n",
            "Completed training batch 68 Training Loss is: 0.3572 Validation Loss is: 0.4264 Accuracy is 77 %\n",
            "Completed training batch 69 Training Loss is: 0.3205 Validation Loss is: 0.4199 Accuracy is 77 %\n",
            "Completed training batch 70 Training Loss is: 0.3256 Validation Loss is: 0.4470 Accuracy is 75 %\n",
            "Completed training batch 71 Training Loss is: 0.3313 Validation Loss is: 0.4574 Accuracy is 75 %\n",
            "Completed training batch 72 Training Loss is: 0.2890 Validation Loss is: 0.4532 Accuracy is 75 %\n",
            "Completed training batch 73 Training Loss is: 0.2887 Validation Loss is: 0.4823 Accuracy is 75 %\n",
            "Completed training batch 74 Training Loss is: 0.2871 Validation Loss is: 0.7224 Accuracy is 66 %\n",
            "Completed training batch 75 Training Loss is: 0.2776 Validation Loss is: 0.5081 Accuracy is 75 %\n",
            "Completed training batch 76 Training Loss is: 0.3336 Validation Loss is: 0.6216 Accuracy is 69 %\n",
            "Completed training batch 77 Training Loss is: 0.2430 Validation Loss is: 0.3898 Accuracy is 83 %\n",
            "Completed training batch 78 Training Loss is: 0.4147 Validation Loss is: 0.1941 Accuracy is 97 %\n",
            "Completed training batch 79 Training Loss is: 0.2094 Validation Loss is: 0.8994 Accuracy is 66 %\n",
            "Completed training batch 80 Training Loss is: 0.2634 Validation Loss is: 0.3703 Accuracy is 83 %\n",
            "Completed training batch 81 Training Loss is: 0.3857 Validation Loss is: 0.1808 Accuracy is 97 %\n",
            "Completed training batch 82 Training Loss is: 0.1966 Validation Loss is: 0.9405 Accuracy is 66 %\n",
            "Completed training batch 83 Training Loss is: 0.2570 Validation Loss is: 0.3024 Accuracy is 86 %\n",
            "Completed training batch 84 Training Loss is: 0.4049 Validation Loss is: 0.2917 Accuracy is 88 %\n",
            "Completed training batch 85 Training Loss is: 0.3738 Validation Loss is: 0.8658 Accuracy is 66 %\n",
            "Completed training batch 86 Training Loss is: 0.2509 Validation Loss is: 0.2427 Accuracy is 88 %\n",
            "Completed training batch 87 Training Loss is: 0.3052 Validation Loss is: 0.5609 Accuracy is 75 %\n",
            "Completed training batch 88 Training Loss is: 0.2099 Validation Loss is: 0.2619 Accuracy is 88 %\n",
            "Completed training batch 89 Training Loss is: 0.2953 Validation Loss is: 0.4793 Accuracy is 77 %\n",
            "Completed training batch 90 Training Loss is: 0.1831 Validation Loss is: 0.2574 Accuracy is 88 %\n",
            "Completed training batch 91 Training Loss is: 0.2045 Validation Loss is: 0.3469 Accuracy is 83 %\n",
            "Completed training batch 92 Training Loss is: 0.2973 Validation Loss is: 0.2309 Accuracy is 88 %\n",
            "Completed training batch 93 Training Loss is: 0.1633 Validation Loss is: 0.2832 Accuracy is 88 %\n",
            "Completed training batch 94 Training Loss is: 0.2070 Validation Loss is: 0.2866 Accuracy is 88 %\n",
            "Completed training batch 95 Training Loss is: 0.2024 Validation Loss is: 0.2724 Accuracy is 88 %\n",
            "Completed training batch 96 Training Loss is: 0.1889 Validation Loss is: 0.2676 Accuracy is 88 %\n",
            "Completed training batch 97 Training Loss is: 0.1843 Validation Loss is: 0.2623 Accuracy is 88 %\n",
            "Completed training batch 98 Training Loss is: 0.1760 Validation Loss is: 0.2529 Accuracy is 88 %\n",
            "Completed training batch 99 Training Loss is: 0.1681 Validation Loss is: 0.2417 Accuracy is 88 %\n",
            "Completed training batch 100 Training Loss is: 0.1597 Validation Loss is: 0.2390 Accuracy is 88 %\n",
            "Completed training batch 101 Training Loss is: 0.1577 Validation Loss is: 0.2351 Accuracy is 88 %\n",
            "Completed training batch 102 Training Loss is: 0.1540 Validation Loss is: 0.2306 Accuracy is 88 %\n",
            "Completed training batch 103 Training Loss is: 0.1487 Validation Loss is: 0.2191 Accuracy is 91 %\n",
            "Completed training batch 104 Training Loss is: 0.1388 Validation Loss is: 0.2163 Accuracy is 91 %\n",
            "Completed training batch 105 Training Loss is: 0.1355 Validation Loss is: 0.2177 Accuracy is 91 %\n",
            "Completed training batch 106 Training Loss is: 0.1377 Validation Loss is: 0.2146 Accuracy is 91 %\n",
            "Completed training batch 107 Training Loss is: 0.1339 Validation Loss is: 0.2003 Accuracy is 91 %\n",
            "Completed training batch 108 Training Loss is: 0.1198 Validation Loss is: 0.2005 Accuracy is 91 %\n",
            "Completed training batch 109 Training Loss is: 0.1169 Validation Loss is: 0.1947 Accuracy is 91 %\n",
            "Completed training batch 110 Training Loss is: 0.1135 Validation Loss is: 0.1961 Accuracy is 91 %\n",
            "Completed training batch 111 Training Loss is: 0.1159 Validation Loss is: 0.1915 Accuracy is 91 %\n",
            "Completed training batch 112 Training Loss is: 0.1124 Validation Loss is: 0.1906 Accuracy is 91 %\n",
            "Completed training batch 113 Training Loss is: 0.1120 Validation Loss is: 0.1893 Accuracy is 91 %\n",
            "Completed training batch 114 Training Loss is: 0.1120 Validation Loss is: 0.1879 Accuracy is 94 %\n",
            "Completed training batch 115 Training Loss is: 0.1110 Validation Loss is: 0.1864 Accuracy is 94 %\n",
            "Completed training batch 116 Training Loss is: 0.1094 Validation Loss is: 0.1849 Accuracy is 94 %\n",
            "Completed training batch 117 Training Loss is: 0.1084 Validation Loss is: 0.1786 Accuracy is 94 %\n",
            "Completed training batch 118 Training Loss is: 0.1015 Validation Loss is: 0.1777 Accuracy is 94 %\n",
            "Completed training batch 119 Training Loss is: 0.1011 Validation Loss is: 0.1770 Accuracy is 94 %\n",
            "Completed training batch 120 Training Loss is: 0.1005 Validation Loss is: 0.1764 Accuracy is 94 %\n",
            "Completed training batch 121 Training Loss is: 0.1004 Validation Loss is: 0.1781 Accuracy is 94 %\n",
            "Completed training batch 122 Training Loss is: 0.1028 Validation Loss is: 0.1776 Accuracy is 94 %\n",
            "Completed training batch 123 Training Loss is: 0.1023 Validation Loss is: 0.1781 Accuracy is 94 %\n",
            "Completed training batch 124 Training Loss is: 0.1029 Validation Loss is: 0.1814 Accuracy is 94 %\n",
            "Completed training batch 125 Training Loss is: 0.1080 Validation Loss is: 0.1819 Accuracy is 94 %\n",
            "Completed training batch 126 Training Loss is: 0.1105 Validation Loss is: 0.1802 Accuracy is 94 %\n",
            "Completed training batch 127 Training Loss is: 0.1066 Validation Loss is: 0.1737 Accuracy is 94 %\n",
            "Completed training batch 128 Training Loss is: 0.0970 Validation Loss is: 0.1714 Accuracy is 94 %\n",
            "Completed training batch 129 Training Loss is: 0.0920 Validation Loss is: 0.1705 Accuracy is 94 %\n",
            "Completed training batch 130 Training Loss is: 0.0910 Validation Loss is: 0.1709 Accuracy is 94 %\n",
            "Completed training batch 131 Training Loss is: 0.0940 Validation Loss is: 0.1696 Accuracy is 94 %\n",
            "Completed training batch 132 Training Loss is: 0.0899 Validation Loss is: 0.1678 Accuracy is 97 %\n",
            "Completed training batch 133 Training Loss is: 0.0926 Validation Loss is: 0.1755 Accuracy is 94 %\n",
            "Completed training batch 134 Training Loss is: 0.1020 Validation Loss is: 0.1659 Accuracy is 97 %\n",
            "Completed training batch 135 Training Loss is: 0.0874 Validation Loss is: 0.1692 Accuracy is 97 %\n",
            "Completed training batch 136 Training Loss is: 0.0917 Validation Loss is: 0.1744 Accuracy is 94 %\n",
            "Completed training batch 137 Training Loss is: 0.1004 Validation Loss is: 0.1744 Accuracy is 94 %\n",
            "Completed training batch 138 Training Loss is: 0.0992 Validation Loss is: 0.1746 Accuracy is 94 %\n",
            "Completed training batch 139 Training Loss is: 0.0958 Validation Loss is: 0.1751 Accuracy is 94 %\n",
            "Completed training batch 140 Training Loss is: 0.0992 Validation Loss is: 0.1659 Accuracy is 97 %\n",
            "Completed training batch 141 Training Loss is: 0.0859 Validation Loss is: 0.1744 Accuracy is 94 %\n",
            "Completed training batch 142 Training Loss is: 0.0960 Validation Loss is: 0.1664 Accuracy is 97 %\n",
            "Completed training batch 143 Training Loss is: 0.0862 Validation Loss is: 0.1738 Accuracy is 97 %\n",
            "Completed training batch 144 Training Loss is: 0.0943 Validation Loss is: 0.1671 Accuracy is 97 %\n",
            "Completed training batch 145 Training Loss is: 0.0874 Validation Loss is: 0.1731 Accuracy is 97 %\n",
            "Completed training batch 146 Training Loss is: 0.0923 Validation Loss is: 0.1676 Accuracy is 97 %\n",
            "Completed training batch 147 Training Loss is: 0.0876 Validation Loss is: 0.1651 Accuracy is 97 %\n",
            "Completed training batch 148 Training Loss is: 0.0829 Validation Loss is: 0.1688 Accuracy is 97 %\n",
            "Completed training batch 149 Training Loss is: 0.0902 Validation Loss is: 0.1675 Accuracy is 97 %\n",
            "Completed training batch 150 Training Loss is: 0.0859 Validation Loss is: 0.1665 Accuracy is 97 %\n",
            "Finished Training\n",
            "\n",
            "Test Accuracy is: 96 %\n"
          ]
        }
      ]
    }
  ]
}